\begin{bio}

\textbf{Mrinmaya Sachan} is a final-year PhD student at
Carnegie Mellon University advised by Prof. Eric
Xing. His work focuses on building automated
solvers for standardized tests using instructional
material. He also loves problems in NLP, Structured
Prediction and Statistical Machine Learning.
His work on machine comprehension was
one of the outstanding papers at ACL 2015. He
has been awarded a number of fellowships namely
the Siebel Scholarship (2013-14), IBM Fellowship
(2016-17) and CMLH Fellowship (2017-18).
He was also a finalist for the Facebook Fellowship
in 2014-15. He regularly publishes in top
NLP conferences. 

\textbf{Minjoon Seo} is a research scientist at NAVER
Clova and a Ph.D. candidate in the Allen School
of Computer Science \& Engineering at the University
of Washington. He is advised by Hannaneh
Hajishirzi, Ali Farhadi and Oren Etzioni. He is
interested in question-driven learning models for
extracting, accessing, and combining knowledge
from natural language. He has served as a program
committee member in ACL, EMNLP, ICLR, and
AAAI. He recently won AI2 Key Scientific Challenges
Award (2018). Previously, he received B.S.
at the University of California, Berkeley. 

\textbf{Hannaneh Hajishirzi} is an assistant research professor
in the Department of Electrical Engineering
and an adjunct assistant professor in the Allen
School of Computer Science \& Engineering at the
University of Washington. Her research interests
are in natural language processing, machine learning,
and artificial intelligence. Her research is currently
focused designing algorithms for semantic
understanding, question answering, and information
extraction about different types of textual and
visual data such as web data, news articles, scientific
articles, and conversations. Her prior research
was on designing statistical relational frameworks
to learn, control, and reason about complex dynamic
domains. 

\textbf{Eric P. Xing} is a professor in the School of
Computer Science at Carnegie Mellon University. His principal research interests lie in the development
of machine learning and statistical methodology,
and large-scale computational system and
architecture, for solving problems involving automated
learning, reasoning, and decision-making
in high-dimensional, multi-modal, and dynamic
possible worlds in complex systems. Professor
Xing received a Ph.D. in Molecular Biology from
Rutgers University, and another Ph.D. in Computer
Science from UC Berkeley. His current
work involves, 1) foundations of statistical learning,
including theory and algorithms for estimating
time/space varying-coefficient models, sparse
structured input/output models, and nonparametric
Bayesian models; 2) framework for parallel
machine learning on big data with big model in
distributed systems or in the cloud; 3) computational
and statistical analysis of gene regulation,
genetic variation, and disease associations;
and 4) application of statistical learning in natural
language, social networks, data mining, and
vision. Professor Xing has published over 200
peer-reviewed papers, and is an associate editor
of the Journal of the American Statistical Association,
Annals of Applied Statistics, the IEEE Transactions
of Pattern Analysis and Machine Intelligence, the PLoS Journal of Computational Biology,
and an Action Editor of the Machine Learning
journal, and the Journal of Machine Learning
Research. He is a member of the DARPA Information
Science and Technology (ISAT) Advisory
Group, a recipient of the NSF Career Award, the
Alfred P. Sloan Research Fellowship, the United
States Air Force Young Investigator Award, and
the IBM Open Collaborative Research Faculty
Award. 
\end{bio}

\begin{tutorial}
  {Standardized Tests as benchmarks for Artificial Intelligence}
  {tutorial-final-005}
  {\daydateyear, \tutorialmorningtime}
  {\TutLocE}

Standardized tests have recently been proposed as replacements to the Turing test as a driver for progress in AI (Clark, 2015). These include tests on understanding passages and stories and answering questions about them (Richardson et al., 2013; Rajpurkar et al., 2016a, inter alia), science question answering (Schoenick et al., 2016, inter alia), algebra word problems (Kushman et al., 2014, inter alia), geometry problems (Seo et al., 2015; Sachan et al., 2016), visual question answering (Antol et al., 2015), etc. Many of these tests require sophisticated understanding of the world, aiming to push the boundaries of AI.

For this tutorial, we broadly categorize these tests into two categories: open domain tests such as reading comprehensions and elementary school tests where the goal is to find the support for an answer from the student curriculum, and closed domain tests such as intermediate level math and science tests (algebra, geometry, Newtonian physics problems, etc.). Unlike open domain tests, closed domain tests require the system to have significant domain knowledge and reasoning capabilities. For example, geometry questions typically involve a number of geometry primitives (lines, quadrilaterals, circles, etc) and require students to use axioms and theorems of geometry (Pythagoras theorem, alternating angles, etc) to solve them. These closed domains often have a formal logical basis and the question can be mapped to a formal language by semantic parsing. The formal question representation can then provided as an input to an expert system to solve the question.

\end{tutorial}
