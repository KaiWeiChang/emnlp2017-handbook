\begin{bio}
\textbf{Matt Gardner} is a research scientist at the Allen
Institute for Artificial Intelligence. His research
focuses on question answering and semantic parsing.
He is the lead designer of the AllenNLP
toolkit, and a host of the NLP Highlights podcast.

\textbf{Joel Grus} is a research engineer at the Allen Institute for Artificial Intelligence, where he works
on problems at the intersection of engineering and
machine learning. He is the author of Data Science
from Scratch: First Principles with Python,
the viral ``Fizz Buzz in Tensorflow'' blog post,
and the ``Livecoding Madness: Let's Build a Deep
Learning Library'' video.

\textbf{Mark Neumann} is a research engineer at the
Allen Institute for Artificial Intelligence, where he
supports research on deep representation learning
and natural language processing. He is a core developer
of the AllenNLP toolkit.

\textbf{Nicholas Lourie} is a research engineer at the
Allen Institute for Artificial Intelligence. Previously,
he worked on large scale processing and
information extraction from scientific documents.
Currently, he works on the AllenNLP toolkit and
NLP research.

\end{bio}

\begin{tutorial}
  {Writing Code for NLP Research}
  {tutorial-final-003}
  {\daydateyear, \tutorialafternoontime}
  {\TutLocC}

Doing modern NLP research requires writing code. Good code enables fast prototyping, easy debugging, controlled experiments, and accessible visualizations that help researchers understand what a model is doing. Bad code leads to research that is at best hard to reproduce and extend, and at worst simply incorrect. Indeed, there is a growing recognition of the importance of having good tools to assist good research in our field, as the upcoming workshop on open source software for NLP demonstrates. This tutorial aims to share best practices for writing code for NLP research, drawing on the instructors' experience designing the recently-released AllenNLP toolkit, a PyTorch-based library for deep learning NLP research. We will explain how a library with the right abstractions and components enables better code and better science, using models implemented in AllenNLP as examples. Participants will learn how to write research code in a way that facilitates good science and easy experimentation, regardless of what framework they use.

\end{tutorial}
