The morphological inflection generation task is to predict the inflected form given a lemma and a set of morpho-syntactic features. We focus on neural network approaches that can tackle the task in a limited-resource setting. As the transduction of the lemma into the inflected form is dominated by copying over lemma characters, we propose two recurrent neural network architectures with monotonic hard attention that are strong at copying and, yet, substantially different in how they achieve this. In the first approach we integrate a copy mechanism to the character-level encoder-decoder model with hard monotonic attention. The second approach is a neural state-transition system over a set of explicit edit actions, including a designated COPY action. We experiment with hard character alignment and find that greedy and eager alignment consistently produces strong results for some languages. Our best system combination is an overall winner in the Task 1 of the SIGMORPHON 2017 in the basic setting (without external resources).
