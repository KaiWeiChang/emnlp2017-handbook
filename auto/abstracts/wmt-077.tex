This paper presents the contribution of the Unbabel team to the WMT 2017 Shared Task on Translation Quality Estimation. We participated on the word-level and sentence-level tracks. We describe our two submitted systems: (i) StackedQE, a ``pure'' QE system, trained only on the provided training sets, which is a stacked combination of a feature-rich sequential linear model with a neural network, and (ii) FullStackedQE, which also stacks the predictions of an automatic post-editing system, trained on additional data. When evaluated on the English-German and German-English datasets, FullStackedQE achieved word-level F1-MULT scores of 56.6\% and 52.9\%, and sentence-level correlation Pearson scores of 64.1\% and 62.6\%, respectively. Our system ranked second in both tracks, being statistically indistinguishable from the best system in the word-level track.
