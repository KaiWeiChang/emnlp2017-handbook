The WMT18 shared task on parallel corpus filtering challenged teams to score sentence pairs from a large high-recall, low-precision web-scraped parallel corpus.  Participants could use existing sample corpora (e.g. past WMT data) as a supervisory signal to learn what a ``clean'' corpus looks like.  However, in lower-resource situations it often happens that the target corpus of the language is the only sample of parallel text in that language. We therefore made several unsupervised entries, setting ourselves an additional constraint that we not utilize the additional clean parallel corpora. One such entry fairly consistently scored in the top ten systems in the 100M-word conditions, and for one task -- translating the European Medicines Agency corpus -- scored among the best systems even in the 10M-word conditions.
