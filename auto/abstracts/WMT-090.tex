This paper describes the unsupervised neural machine translation (NMT) systems of the RWTH Aachen University developed for the English to and from German news translation task of WMT 2018. Our work is based on iterative back-translation using a shared encoder-decoder NMT model. We extensively compare different vocabulary types, word embedding initialization schemes and optimization methods for our model. We also investigate gating and weight normalization for the word embedding layer.
