With huge amount of information generated every day on the web, fact checking is an im- portant and challenging task which can help people identify the authenticity of most claims as well as providing evidences selected from knowledge source like Wikipedia. Here we decompose this problem into two parts: an en- tity linking task (retrieving relative Wikipedia pages) and recognizing textual entailment be- tween the claim and selected pages. In this pa- per, we present an end-to-end multi-task learn- ing with bi-direction attention (EMBA) model to classify the claim as ``supports'', ``refutes'' or ``not enough info'' with respect to the pages retrieved and detect sentences as evidence at the same time. We conduct experiments on the FEVER (Fact Extraction and VERification) paper test dataset and shared task test dataset, a new public dataset for verification against tex- tual sources. Experimental results show that our method achieves comparable performance compared with the baseline system.
