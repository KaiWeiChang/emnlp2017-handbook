In state-of-the-art Neural Machine Trans- lation (NMT), an attention mechanism is used during decoding to enhance the trans- lation. At every step, the decoder uses this mechanism to focus on different parts of the source sentence to gather the most use- ful information before outputting its tar- get word. Recently, the effectiveness of the attention mechanism has also been ex- plored for multi-modal tasks, where it be- comes possible to focus both on sentence parts and image regions that they describe. In this paper, we compare several atten- tion mechanism on the multi-modal trans- lation task (English, image â†’ German) and evaluate the ability of the model to make use of images to improve translation. We surpass state-of-the-art scores on the Multi30k data set, we nevertheless iden- tify and report different misbehavior of the machine while translating.
