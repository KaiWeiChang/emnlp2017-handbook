Automatic post-editing (APE) is a challenging task on WMT evaluation campaign. Through data analysis of the training set of WMT17 APE en-de task, we find that only a small number of edit operations are required for many machine translation outputs to correct them into good translations. At this point two neural post-editing (NPE) models are trained in term of the edit numbers, single edit and minor edits. The improved quality estimation (QE) approach is exploited to select the best model, and rank the n-best list translation hypotheses generated by the best APE model and the raw translation system. Experimental results on the datasets of WMT16 APE test set show that the proposed approach statistically outperforms the baseline. Deep analysis further confirms that our approach can bring considerable relief from the overcorrection problem in APE.
