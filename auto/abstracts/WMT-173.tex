We describe our NMT system submitted to the WMT2018 shared task in news translation. Our system is based on the Transformer model \citep{vaswani-et-al:2017}. We use an improved technique of backtranslation, where we iterate the process of translating monolingual data in one direction and training an NMT model for the opposite direction using synthetic parallel data. We apply a simple but effective filtering of the synthetic data. We pre-process the input sentences using coreference resolution in order to disambiguate the gender of pro-dropped personal pronouns. Finally, we apply two simple post-processing substitutions on the translated output. Our system is significantly (\$p < 0.05\$) better than all other English-Czech and Czech-English systems in WMT2018.
