We propose an approach to N -best list re- ranking using neural sequence-labelling models. We train a compositional model for error detection that calculates the prob- ability of each token in a sentence being correct or incorrect, utilising the full sen- tence as context. Using the error detec- tion model, we then re-rank the N best hypotheses generated by statistical ma- chine translation systems. Our approach achieves state-of-the-art results on error correction for three different datasets, and it has the additional advantage of only us- ing a small set of easily computed features that require no linguistic input.
