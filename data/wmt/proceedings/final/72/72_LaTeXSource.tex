\documentclass[11pt,letterpaper,final,nohyperref]{article}
\usepackage{emnlp2017}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{latexsym}

% Uncomment this line for the final submission:
\emnlpfinalcopy

%  Enter the EMNLP Paper ID here:
\def\emnlppaperid{***}

% To expand the titlebox for more authors, uncomment
% below and set accordingly.
% \addtolength\titlebox{.5in}    

\newcommand\BibTeX{B{\sc ib}\TeX}
\usepackage{url}
\usepackage{booktabs}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage[draft]{fixme}
\usepackage{bm}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{array}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{todonotes}
\usepackage{nth}
\usepackage{pgfplots}
\usepgfplotslibrary{groupplots}

\fxsetup{theme=color}

\newcommand{\vect}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\aseq}{\ensuremath{\mathbf{\asymb}}} % alignment sentence
\newcommand{\src}{\ensuremath{\mathbf{f}}} % source sentence
\newcommand{\trg}{\ensuremath{\mathbf{e}}} % target sentence

\SetKwProg{Fn}{Function}{}{end}
\SetKwInput{Input}{input}

\setlength{\textfloatsep}{16pt plus 2.0pt minus 2.0pt}

% Uncomment this line for the final submission:
% \emnlpfinalcopy

%  Enter the EMNLP Paper ID here:
% \def\emnlppaperid{555}

% To expand the titlebox for more authors, uncomment
% below and set accordingly.
% \addtolength\titlebox{.5in}    

%\title{``Neural Machine Translation improving morphology ? `` a systematic reevalution}
\title{Evaluating the morphological competence of Machine Translation Systems}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   {\tt email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   {\tt email@domain} \\}

 \author{Franck Burlot \and Fran\c{c}ois Yvon \\
         LIMSI, CNRS, Universit√© Paris-Saclay, France \\
 {\tt firstname.lastname@limsi.fr}}


\date{}

\begin{document}

\maketitle
\begin{abstract}
While recent changes in Machine Translation state-of-the-art
brought translation quality a step further, it is regularly acknowledged 
that the standard automatic metrics do not provide enough insights
to fully measure the impact of neural models.
This paper 
% introduces a short review of the different
% methods used to assess Machine Translation quality
% and 
proposes a new type of evaluation focused specifically
on the morphological competence of a system with respect
to various grammatical phenomena. Our approach uses automatically generated pairs of source sentences, where each pair tests one morphological contrast. 
This methodology is used to compare several systems submitted
at WMT'17 for English into Czech and Latvian.
\end{abstract}

\section{Introduction \label{sec:introduction}}
It is nowadays unanimously recognized that Machine Translation (MT) engines based on the neural encoder-decoder architecture with attention \cite{Cho14properties,Bahdanau15NMT} constitute the new state-of-the-art in statistical MT, at least for open-domain tasks \cite{Sennrich16WMT}. The previous phrase-based (PBMT) architectures were complex \cite{Koehn10smt} and hard to diagnose, and Neural MT (NMT) systems, which dispense with any sort of symbolic representation of the learned knowledge, are probably worse in this respect. Furthermore, the steady progress of MT engines makes 
% conventional 
automatic metrics such as BLEU \citep{Papineni02bleu} or METEOR \cite{Banerjee05meteor} less 
% and less 
appropriate to evaluate and compare modern NMT systems. To better understand the strength and 
% remaining 
weaknesses of these new architectures, it is thus necessary to investigate new, more focused, evaluation procedures.

Error analysis protocols, as proposed eg.\ by \citet{Vilar06error,Popovic11towards} for PBMT, are obvious candidates for such studies and have been used eg.\ in \citep{Bentivogli16neural}. Recently, various new proposals have been put forward to better diagnose neural models, notably by \citet{Linzen16assessing,Sennrich17howgrammatical}, who focus respectively on the syntactic competence of Neural Language Models (NLMs) or of NMT; and by \citet{Isabelle17challenge, Burchardt17linguistic}, who resuscitate an old tradition of designing test suites.  

Inspired by these (and other) works (see \textsection{}~\ref{sec:related}), we propose in this paper a new evaluation scheme aimed at specifically assessing the \emph{morphological} competence of MT engines translating from English into a Morphologically Rich Language (MRL). Morphology poses two main types of problems in MT: (a) morphological variation in the source increases the occurrence of Out-of-Vocabulary (OOV) source tokens, the translation of which is difficult to coin; (b) morphological variation in the target forces the MT to generate forms that have not been seen in training. 
% Problems (a) and (b) can appear in isolation, or even be compounded. 
Morphological complexity is alo often associated to more flexible word orderings, which is mostly a problem when translating from a MRL \cite{bisazza16reorder}. Reducing these issues is a legitimate and important goal for many language pairs.

Our method for measuring the morphological competence of MT systems (detailed in \textsection~\ref{sec:protocol}) is mainly based on the analysis of minimal pairs, each representing a contrast that is expressed syntactically in English and morphologically in the MRL. By comparing the automatic translations of these pairs, it is then possible to approximately assess whether a given MT system has succeeded in generating the correct word form, carrying the proper morphological marks. In \textsection~\ref{sec:experiments}, we illustrate the potential of our evaluation protocol in a large-scale comparison of multiple MT engines having participated to the WMT'17 News Translation tasks for the pairs English-Czech and English-Latvian.\footnote{\url{http://statmt.org/wmt17/}.}
% \citep{Bojar17findings}. 
We finally relate our protocol to conventional metrics (\textsection{}~\ref{sec:related}), and conclude in \textsection{}~\ref{sec:conclusion} by discussing possible extensions of this methodology, for instance to other (sets of) language pairs.

\section{Evaluation Protocol \label{sec:protocol}}

\subsection{Morphological competence and its assessment }

In traditional linguistics, morphology is ``the branch of the grammar that deals with the internal structure of words'' \cite[p.~9]{Matthews74morphology}; the ``structure of words'' being further subdivided into inflections, derivations (word formation) and compounds. Languages exhibit a large variety of formal processes to express morphological/lexical relatedness of a set of word forms: alternations in suffix/prefix are the most common processes in Indo-European languages, where other language families recourse to circumfixation, reduplication, transfixation, or tonal alternations. They also greatly differ in the phenomena that are expressed through morphological alternations versus grammatical constructions. 

Our evaluation protocol is designed to assess the robustness of MT in the presence of morphological variation in the source and target, looking how source alternations (possibly implying to translate source OOVs) are reproduced in the target (possibly implying to generate target OOVs).

The general principle is as follows: for each source test sentence (the \emph{base}), we generate one (or several) \emph{variant(s)} containing exactly one difference with the base, focusing on a specific \emph{target} lexeme of the base; the variant differs on a feature that is expressed morphologically in the target, such as the person, number or tense of a verb; or the number or case of a noun or an adjective. This configuration is illustrated in Table~\ref{tab:contrast}, where the first pair is an example of the \emph{tense} contrast and the second pair an instance of the \emph{polarity} contrast.

\begin{table*}[t]
  \centering
  \begin{tabular}{ll}
    base & (1.a) The thing that \textbf{horrifies} me is the forgetfulness. \\
    variant & (1.b) The thing that \textbf{horrified} me is the forgetfulness. \\ \hline
    base & (2.a)  Traffic deaths \textbf{fall} as gas prices climb. \\
    variant & (2.b) Traffic deaths \textbf{do not fall} as gas prices climb. \\ \hline
  \end{tabular}
  \caption{Generating minimal contrastive pairs}
  \label{tab:contrast}
\end{table*}

We consider that a system behaves correctly with respect to a 
given contrast if the translation of the base and the variant 
reproduce the targeted contrast: for the first example in 
Table~\ref{tab:contrast}, we expect to see
in the translation of (1.a) and (1.b) different word forms
accounting for the difference of verb tense: the translation
of the variant should have a past form and any other case is
considered as an error. Other modifications between the
two translations, such as the selection of different lemmas
for both forms or any modification of the context, are considered
irrelevant with respect to the specific morphological feature at study,
and are therefore ignored.
%% the same verb lemma in the translation of (1.a) and (1.b) but different word forms accounting for the difference of verb tense: all other configurations (different lexemes, multiples morphological differences) will count as an error.
In the following sections, we detail and justify our strategy for generating contrastive pairs.

\subsection{Sentence selection and morphological contrasts \label{ssec:selection}}

We consider the set of contrasts listed in Table~\ref{tab:allcontrasts}. We distinguish three subsets (denoted A, B, and C), which slightly differ in their generation and scoring procedures. 
\begin{table*}[t]
  \centering
  \begin{tabular}{lllp{0.6\textwidth}}
    name & contrast & target & description \\ \hline
    A-1 & number & noun & base contains a singular noun, variant contains the plural form \\
    A-2 & number & pronoun & base contains a singular pronoun, variant contains the plural form \\
    A-3 & gender & pronoun & base contains a masculine pronoun, variant contains the feminine form \\
    A-4 & tense:future & verb & base and variant only differ in the tense of the main verb - present in the base, future in the variant\\
    A-5 & tense:past   & verb & base and variant only differ in the tense of the main verb - present in the base, past in the variant\\
    A-6 & comparative & adjective & base contains the bare adjective, variant the comparative form \\ 
    A-7 & polarity   & verb & base and variant only differ in the polarity of the main verb - affirmative in the base, negative in the variant\\
\hline
    B-1 & complex NP & pronoun & base contains a pronoun, variant contains a complex NP of the form \emph{adj noun} \\
    B-2 & coordinated noun & pronoun & base contains a pronoun, variant contains a coordinated NP of the form \emph{noun and noun} \\ 
    B-3 & coordinated verbs & verbs & base contain a simple verb, variant contains a coordinated VP of the form \emph{verb and verb} \\
    B-4 & prep-case & preposition & base and variant differ in one preposition which implies a different case in the target (eg. \emph{during} vs.\ \emph{before}, \emph{with} vs.\ \emph{without}) \\
\hline
    C-1 & hyponyms & adjective & base contains an adjective, (4) variants with hyponyms \\
    C-2 & hyponyms & noun & base contains a noun, (4) variants with hyponyms \\
    C-3 & hyponyms & verb & base contains a verb, (4) variants with hyponyms \\
  \end{tabular}
  \caption{A set of morphological contrasts. See text for details.}
  \label{tab:allcontrasts}
\end{table*}
%\fxnote{why does coordinated noun differ}

Our choice for selecting this particular set of tests was dictated by a mixture of linguistic and also more practical reasons. From a linguistic standpoint, we were looking to cover a large variety of morphological phenomena in the target language, in particular we wished to include test instances for all open domain word classes (noun, verbs, adjectives). Our first set of tests (set A) is akin to paradigm completion tasks, adopting here a rather loose sense of ``paradigm'' which also includes simple derivational phenomena such as the formation of comparative for adjectives and mostly checks whether the morphological feature inserted in the source sentence has been translated. Tests in the set B look at various agreement phenomena, while tests in set C are more focused on the consistency of morphological choices. These three categories of tests slightly differ in their generation and scoring procedures.

For each contrast in the A and B sets, sentence generation takes the following steps:\footnote{Examples of test pairs are given as supplementary material in the appendix.}
\begin{enumerate}
\item collect a sufficiently large number of short sentences (length $<$ 15) containing a source word
  of interest for at least one morphological variation; 
\item generate a variant as prescribed by the contrast (see below);
\item compute an average language model (LM) score for the pair (base, variant);
\item remove the 33\% worst pairs based on their LM score;
\item randomly select 500 pairs for inclusion into the final test.
\end{enumerate}

For set A, the creation of the variant (step~2) consists in replacing a word according to the morphological phenomenon to evaluate (see examples Table~\ref{tab:contrast}). This word is selected in such a way that its modification does not require a modification of any other word in the sentence. For instance, a singular subject noun is not replaced by its plural form, since the verb agreeing with it would also need to be replaced accordingly. Indeed, more than one modification would go against our initial idea of generating minimal pairs reflecting exactly one single contrast.

For B-1 (complex NPs), we spot a personal pronoun that we changed into an NP consisting in an adjective and a noun. Both words are generated randomly with
the only constraint that the noun should refer to a human subject and the adjective to a psychological state, yielding NPs such as ``the happy linguist'' or ``the gloomy philosopher''.  In order to ensure that the context corresponds to a human subject, we selected pronouns that unambiguously refer to humans, such as ``him'', ``her'', ``we''
(avoiding ``them''). 
For B-2 (coordinated NPs) the pronoun in the base sentence is transformed into a complex NP consisting of two
coordinated nouns. Note that adjectives associated to these nouns, as well as adverbs, have been randomly inserted in order to produce some variation in the constructions.
The B-3 contrasts are produced in a similar fashion, targeting verbs instead of nouns, with an additional random generation of a discourse marker that should not interfere with the translation, yielding variants like ``he \textbf{said} and\underline{, as a matter of fact,} \textbf{shouted}''.\footnote{The coordinated verbs are in bold, the discourse marker is underlined.}
Those insertions were performed in order to increase the distance between the two verbs, making agreement between them harder.
Finally, the B-4 contrasts are produced in the same way as for the A-set and simply consist in modifying a preposition.

The C-set variants select a noun, an adjective or a verb and replace it with a random hyponym, producing an arbitrary number of
sentences. Sentence selection slightly differs from the description above: during step 2, we generate as many variants as possible. Each variant is then scored with a language model and only the top four variants are kept, leading to buckets of five sentences. Those buckets are finally filtered in the same way as for the A and B sets, removing the 33\% worst buckets based on their LM score (step~3).

%% For the contrasts in the B-set, the generation step is more complex: for B-1 (complex NPs) we combine a random nominal daughter of the "\fxnote{FIX THIS}" wordnet synset with a  random adjectival daughter of the "\fxnote{FIX THIS}" - yielding NPs such as "the happy linguist" or "the gloomy philosopher" -- \fxnote{Is this true ?} note that intervening adverbs are randomly inserted; for B-2 (coordinated NPs) the variant contains a the base noun and one of its hyponym in Wordnet; the B-3 contrasts, are produced in a similar fashion, targeting verbs instead of nouns.
%% \fxnote{how to control for case ?}

All the sentences were selected
from the English News-2008 corpus provided
at WMT. The choice of the news domain was dictated by our intention
to evaluate systems submitted at WMT'17\footnote{\url{www.statmt.org/wmt17/}} News Translation task.
Sentences longer than 15 tokens were removed in order to ensure a
better focus on a specific part of the sentence in the
MT output.
The modifications of English sentences were based on a morpho-syntactic analysis produced with the TreeTagger \cite{Schmid94pos}
and using the Pymorphy morphological generator\footnote{\url{http://pymorphy.readthedocs.io/}}
to change the inflection of a word. Hyponyms (synonyms and/or antonyms) were generated with WordNet \cite{miller95wordnet}.
The 5-gram language model used for sentence selection was learned with KenLM \cite{Heafield11kenlm} on all English monolingual data available at WMT'15. %% \cite{marie15wmt}

\subsection{Scoring Procedures \label{ssec:scoring}}

Regarding the scoring procedure, we again distinguish three cases (examples are in Table~\ref{table:eval_feat}).
\begin{itemize}
\item  set A: we compare the translations of base and variant and
search for the word(s) in variant that are not in base. If one of these words contains 
the morphological feature associated with the source sentence modification,
we report a success. Accuracy of each morphological feature is averaged over all the samples.
In this set, we thus evaluate morphological information that should be conveyed from the source sentence,
which leads to an assessment on the grammatical adequacy of the output towards the source. 
%report a success if they both contain a lemma of the right target category which varies in feature as prescribed by the contrast EXAMPLE

\item set B: we compare the translations of base and variant and check that (a) a pronoun in the former is replaced by a NP in the latter
(b) the adjective and the noun in the NP share the same gender, number and case.
%% the morphological features of the pronoun match those of all components of the NP 
A distinct accuracy rate per feature can then be reported;
note that the situation is different in the complex and coordinated tests, as in the latter case some agreement properties may differ in the base and variant (eg.\ the NP gender agreement depends on the noun gender that may be different from the pronoun gender in base).
For the test triggered by prepositions (B-4), we check whether the first noun on the right of a preposition
carries the required case mark. Moreover, since we have prepositions associated to nouns in both base and variant, we performed this test on both sentences.
This evaluation set checks for agreement and provides an insight about the morphological fluency of the produced translations.

\item set C : in this set of tests, we wish to assess the consistency of morphological features with respect to lexical variation in a fixed context; accordingly, we measure the success based on the average normalized entropy of morphological features in the set of target sentences. 
% To do so, we compute a simple normalized count of the morphological value bared by the word in each sentence of the bucket.
%% \[
%% H(f) =  \frac{1}{|B|} \sum_{b \in B} \sum_{v \in \text{f}} - \frac{p(v|b) \log p(v|b)}{\log |f|}
%% \]
%% where $f$ is a morphological feature (eg. case), $v$ is its value (nominative), $B$ is the set of all sentence buckets, and
%% $p(v|f)$ is a simple normalized count of the morphological value bared by the word in each sentence of the bucket.
Such scores can be computed either globally or on a per feature basis. The entropy is null when all variants have the same morphological features, the highest possible consistency; conversely, the normalized entropy is 1 when the five sentences contain different morphological features. For each set C-1, C-2 and C-3, we report average scores over 500~samples. In this setup, we measure the degree of certainty to which a system predicts morphological features across small lexical variations.
\end{itemize}

\begin{table*}[t]
\begin{center}
\small
\begin{tabular}{ lll } 
\hline
\textbf{Base\&Variant(s)} & \textbf{Output} & \textbf{Result} \\
\hline
\multicolumn{3}{c}{\textbf{A-set}} \\
\hline
I am hungry & m\'am hlad & \\
I am not hungry & \textbf{nem\'am} hlad & negation found \\
\hline
\multicolumn{3}{c}{\textbf{B-set}} \\
\hline
I see him & vid\'im ho & noun and adjective both \\
I see a crazy researcher & vid\'im \textbf{bl\'azniv\'eho v\'yzkumn\'ika} &  have accusative form \\
\hline
\multicolumn{3}{c}{\textbf{C-set}} \\
\hline
I agree with the president & souhlas\'im s \textbf{prezidentem} &  all nouns bear \\
I agree with the director & souhlas\'im s \textbf{\v{r}editelem} &  the same \\
I agree with the minister & souhlas\'im s \textbf{ministrem} & intrumental case \\
I agree with the driver & souhlas\'im s \textbf{\v{r}idi\v{c}em} &  \\
I agree with the painter & souhlas\'im s \textbf{mal\'i\v{r}em} & (Entropy $=$ 0.0) \\
\hline
 \end{tabular} 
\caption{\label{table:eval_feat} Examples of sentences that pass the tests.}
\end{center}
\end{table*}

Our scoring procedure needs access to morphological information in the target. For A and B sets, the translated sentences are passed through a morphological analysis, where several PoS can be associated with a word. This makes the evaluation less dependent on the tagger's accuracy. Therefore, when checking whether a specific
morphological feature appears in the output (eg.\ negation of a verb), we look for at least one PoS tag indicating negation, ignoring all the others.

For Czech, we used the Morphodita analyzer \cite{strakova14morphodita}. We had no such resource
for Latvian and therefore used the LU MII Tagger \cite{paikens13lv} to parse all Latvian monolingual data available at WMT'17. We then extracted a dictionary consisting of words and associated PoS from the automatic parses.
We finally performed a coarse cleaning of this dictionary by removing the PoS that were predicted less than 100 times for a specific word. To run the morphological analysis of Latvian, we parsed the translated sentences with the tagger, then augmented the tagger predictions with our dictionary, producing the desired ambiguous analysis
of the Latvian outputs.

For the C-set, the translated sentence analyses are disambiguated: each word is mapped to a single PoS.
This was required to compute the entropy. Indeed, we need to select only one morphological value
for each base and variant sentence, given that the entropy is normalized according the total number of sentences
in the bucket.

\section{Experiments \label{sec:experiments}}

We have run the presented morphological evaluation\footnote{The test suite and the scripts used for evaluation can
be downloaded at \url{github.com/franckbrl/morpheval}.}
on several systems among which some were submitted at WMT'17. The description
of the latter can be found in the proceedings of the Second Conference
on Machine Translation \shortcite{wmt2017proc}. We briefly summarize
the types of systems included in the English-to-Czech study:

\begin{itemize}
  \item Phrase-based systems: The \textbf{Moses baseline} was trained on
    WMT'17 data and was not submitted at WMT'17. \textbf{UFAL Chimera}\footnote{
    Chimera \cite{bojar13chimera} consists in a phrase-based factored
    system (Moses), a deep-syntactic transfer-based
    system (TectoMT) and a rule-based post-processing system.}
    was submitted at WMT'16 and is described in \cite{tamchyna16wmt}.
  \item Word based NMT: \textbf{NMT words} is a system trained on
    WMT'17 parallel data with a target vocabulary of 80k tokens. It
    was not submitted at WMT'17 and is used for contrast.
  \item BPE-based NMT: \textbf{LIMSI NMT} \cite{burlot16wmt} is based on NMTPY \cite{nmtpy},
    \textbf{UEDIN NMT} \cite{uedin2017wmt} on Nematus \cite{nematus17} and \textbf{UFAL NMT} \cite{cuniwmt17}
    on Neural Monkey \cite{neuralMonkey17}.
  \item NMT modeling target morphology: \textbf{LIMSI FNMT} \cite{burlot16wmt} and
    \textbf{LIUM FNMT} \cite{garcia2017wmtnews} use a factored output predicting words and PoS,
    and \textbf{UFAL NMT Chim.} \cite{cuniwmt17} uses Chimera \cite{bojar13chimera}. All these
    models also use BPE segmentation.
\end{itemize}

These systems are representative of different
models across statistical MT history. Phrase-based
systems are a former state of the art that word-based
NMT struggled to improve. The new state of the art is
an NMT setup with an open vocabulary provided by byte pair
encoding (BPE) segmentation \cite{Sennrich16BPE}. Finally,
we have a set of systems that are optimized in order
to improve target morphology. The automatic scores of the systems submitted at
WMT'17\footnote{We were not able to provide
such scores for the other systems, since we
did not have access to their translations of WMT'17 official test sets.}
are in Table~\ref{tab:bleuCs} where we report
BLEU, BEER~\cite{Stanojevic14beer} and CharacTER~\cite{Wang16character}.\footnote{Outputs were
taken from \url{matrix.statmt.org}. The scores are computed on tokenized and truecased outputs.}
We also computed a morphology accuracy for these systems.
Using output-to-reference alignments produced by METEOR
on lemmas, we checked whether aligned words shared
the same form. Our assumption
is that two different forms associated to the same lemma
correspond to two different inflections of the same lexeme, which allows us to locate
positions that likely correspond to morphological errors.
% word forms in the hypothesis that are different from the ones observed in the reference translation.

\begin{table}[tb] %%[!htbp]
\begin{center}
\scriptsize %small
\begin{tabular}{ l|cccc } 
\hline
System & BLEU $\uparrow$ & BEER $\uparrow$ & CTER $\downarrow$ & Acc. \\
\hline
\textbf{LIMSI NMT}      & 19.81 & 54.50 & 58.40 & 85.59 \\
\textbf{UFAL NMT}       & 19.78 & 54.52 & 57.62 & 85.31 \\
\textbf{UEDIN NMT}      & 23.06 & 56.52 & 56.04 & 86.98 \\
\textbf{LIMSI FNMT}     & 20.45 & 54.98 & 58.09 & 85.42 \\
\textbf{LIUM FNTM}      & 20.14 & 54.81 & 57.91 & 84.98 \\
\textbf{UFAL NMT Chim.} & 21.00 & 55.04 & 59.39 & 85.28 \\
\hline
 \end{tabular} 
\caption{\label{tab:bleuCs} Scores of the English-to-Czech WMT'17 submissions on the official test set.}
\end{center}
\end{table}


\begin{table*}[tb] %%[!htbp]
\begin{center}
\small
\begin{tabular}{ l|ccc|cc|cc||c } 
\hline
&  \multicolumn{3}{c}{\textbf{verbs}} & \multicolumn{2}{c}{\textbf{pronouns}}  & \multicolumn{2}{c}{\textbf{others}}  & \multicolumn{1}{c}{\textbf{mean}}\\
\hline
System & past & future & neg. & fem. & plur. & noun nb. & compar. & \\
\hline
\textbf{Moses baseline} & 61.0\% & 87.2\% & 73.8\% & 91.6\% & 78.0\% & 72.6\% & 70.9\% & 76.4\% \\
\textbf{UFAL PBMT}      & 92.2\% & \textbf{88.6\%} & 78.8\% & 75.6\% & 79.8\% & 86.0\% & 72.2\% & 81.9\% \\ 
\textbf{NMT words}      & 74.6\% & 60.6\% & 91.6\% & 89.2\% & 71.6\% & 44.0\% & 47.8\% & 68.5\% \\
\textbf{UFAL NMT}       & 91.0\% & 90.4\% & 95.0\% & \textbf{92.4\%} & \textbf{80.8\%} & \textbf{96.6\%} & 70.6\% & 88.1\% \\
\textbf{LIMSI NMT}      & 92.6\% & 86.2\% & \textbf{96.0\%} & 91.4\% & 79.2\% & 94.6\% & \textbf{76.2\%} & 88.0\% \\ 
\textbf{UEDIN NMT}      & 92.4\% & 87.0\% & 94.2\% & 93.0\% & 78.0\% & 95.8\% & 73.8\% & 87.7\% \\
\textbf{LIMSI FNMT}     & 94.2\% & 88.0\% & 95.4\% & 91.2\% & 80.0\% & 96.2\% & 75.0\% & \textbf{88.6\%} \\
\textbf{LIUM FNTM}      & \textbf{93.4\%} & 84.0\% & 94.6\% & 91.6\% & 80.2\% & 96.2\% & 73.4\% & 87.6\% \\
\textbf{UFAL NMT Chim.} & 92.6\% & 86.6\% & 88.2\% & 85.4\% & 80.2\% & 89.2\% & 70.6\% & 84.7\% \\
\hline
 \end{tabular} 
\caption{\label{table:eval_cs_A} Sentence pair evaluation for English-to-Czech (A-set).}
\end{center}
\end{table*}

Table~\ref{table:eval_cs_A} lists the results for the A-set tests,
which evaluate the morphological adequacy of the output wrt.\ the source
sentence. The last column provides the mean of all scores for one system.
We can note that all BPE-based NMT systems have a much
higher performance than the phrase-based systems.\footnote{The prediction quality of
future tense by PBMT systems is however comparable to that of NMT systems.
We assume that this is due to the possibility to generate
an analytic form of this tense (auxiliary + infinitive) that is easier
to form well than its synthetic form (morphological phenomenon).}
We explain the poor performance of the word-based NMT system by the use of a too small
closed vocabulary: over the 18,500 sentences of the test suite, 12,016 unknown
words were produced by this system.
%% This system is unable to generate word forms that have
%% a low frequency in the training data, a serious issue when dealing
%% with MRLs: over the 18,500 sentences of the test suite, 12,016 unknown
%% words were produced by this system.
However, when it comes to predicting the morphology of closed
class words, this systems performs much better: the accuracy computed for pronoun
gender and number is similar to the ones of best BPE-based systems. As opposed
to nouns and verbs (open classes), the set of pronouns in Czech is quite small;
having observed all their inflections, the word-based system is in a better position
to convey the target form.

Despite important differences in automatic metric scores between UEDIN NMT system
and LIMSI FNMT, we see that the latter always outperforms the former, except for the
feminine pronoun prediction. The overall morphological accuracies (Table~\ref{tab:bleuCs})
show that UEDIN NMT provides more similar word forms with the reference translation,
but these global scores fail to show the higher adequacy performance of LIMSI FNMT 
highlighted in the A-set. 
%The next set point out what seems to be the strength of UEDIN NMT: fluency.

\begin{table*}[tb] %%[!htbp]
\begin{center}
\small
\begin{tabular}{ l|ccc|c|ccc|c||c }
\hline
& \multicolumn{3}{c}{\textbf{coordinated verbs}} & \multicolumn{1}{c}{\textbf{coord.n}} & \multicolumn{3}{c}{\textbf{pronouns to nouns}} & \multicolumn{1}{c}{\textbf{prep.}} & \multicolumn{1}{c}{\textbf{mean}}\\
\hline
System & number & person & tense & case & gender & number & case & case & \\
\hline
\textbf{Moses baseline}  & 53.2\% & 53.6\% & 47.6\% & 92.6\% & 68.0\% & 69.4\% & 69.4\% & 86.2\% & 67.5\% \\
\textbf{UFAL PBMT}       & 67.4\% & 69.2\% & 59.2\% & 93.2\% & 92.4\% & 92.4\% & 91.8\% & 89.6\% & 81.9\% \\ 
\textbf{NMT words}       & 60.0\% & 58.8\% & 51.8\% & 64.0\% & 22.8\% & 23.2\% & 22.6\% & 62.2\% & 45.7\% \\
\textbf{LIMSI NMT}       & 76.6\% & 77.0\% & 69.2\% & 90.4\% & 90.8\% & 92.6\% & 92.2\% & 95.3\% & 85.5\% \\
\textbf{UFAL NMT}        & 81.4\% & 80.0\% & 74.0\% & \textbf{94.2\%} & \textbf{94.4\%} & \textbf{94.6\%} & \textbf{94.8\%} & \textbf{97.0\%} & 88.8\% \\
\textbf{UEDIN NMT}       & \textbf{83.6\%} & \textbf{84.2\%} & \textbf{77.6\%} & 92.8\% & 93.6\% & 94.4\% & 94.0\% & 95.8\% & \textbf{89.5\%} \\
\textbf{LIMSI FNMT}      & 77.6\% & 77.4\% & 70.6\% & 89.0\% & 91.4\% & 90.8\% & 91.6\% & 96.1\% & 85.6\% \\
\textbf{LIUM FNTM}       & 80.8\% & 79.6\% & 71.8\% & 89.6\% & 90.6\% & 90.4\% & 90.8\% & 95.8\% & 86.2\% \\
\textbf{UFAL NMT Chim.}  & 75.8\% & 74.6\% & 68.0\% & 92.6\% & 87.8\% & 87.8\% & 88.2\% & 92.9\% & 83.5\% \\
\hline
 \end{tabular} 
\caption{\label{table:eval_cs_B} Sentence pair evaluation for English-to-Czech (B-set).}
\end{center}
\end{table*}


The results of the B-set evaluation for Czech are in Table~\ref{table:eval_cs_B}
and are an estimate of the morphological fluency of the output. We observe here again
that morphological phenomena such as agreement are better modeled by sequence-to-sequence models
using BPE segmentation than phrase-based or word-based NMT systems.
%% Among the former systems, the use of BPE segmentation compared
%% to unsegmented words makes, once again, an important difference. Finally, 
The overall best
performance of UEDIN and UFAL NMT has to be noted, since both outperform systems that explicitly model target
morphology.

\begin{table*}[tb] %%[!htbp]
\begin{center}
\small
\begin{tabular}{ l|c|ccc|cccc||c } 
\hline
& \multicolumn{1}{c}{\textbf{nouns}} & \multicolumn{3}{c}{\textbf{adjectives}} & \multicolumn{4}{c}{\textbf{verbs}} & \multicolumn{1}{c}{\textbf{mean}} \\
\hline
System & case & gender & number & case & number & person & tense & negation & \\
\hline
\textbf{Moses baseline}  & .381 & .482 & .420 & .453 & .415 & .300 & .354 & .269 & .384 \\ 
\textbf{UFAL PBMT}       & .272 & .376 & .331 & .376 & .198 & .134 & .150 & .105 & .243 \\ 
\textbf{NMT words}       & .419 & .561 & .537 & .460 & .513 & .477 & .491 & .467 & .491 \\ 
\textbf{UFAL NMT}        & .193 & .325 & .271 & .317 & .154 & .084 & .105 & .075 & .191 \\ 
\textbf{LIMSI NMT}       & .205 & .303 & .262 & .301 & .138 & .068 & .082 & \textbf{.054} & .177 \\ 
\textbf{UEDIN NMT}       & .217 & .302 & .276 & .300 & .124 & .065 & .086 & \textbf{.054} & .178 \\ 
\textbf{LIMSI FNMT}      & \textbf{.197} & .287 & .255 & .292 & \textbf{.110} & \textbf{.062} & \textbf{.081} & .056 & \textbf{.168} \\
\textbf{LIUM FNTM}       & .206 & \textbf{.278} & \textbf{.240} & \textbf{.269} & .125 & .074 & .090 & .067 & .169 \\ 
\textbf{UFAL NMT Chim.}  & .214 & .353 & .302 & .359 & .185 & .114 & .129 & .097 & .219 \\ 
\hline
 \end{tabular} 
\caption{\label{table:eval_cs_C} Sentence group evaluation for English-to-Czech with Entropy (C-set).}
\end{center}
\end{table*}

The results for the C-set for English-to-Czech are
shown in Table~\ref{table:eval_cs_C}.
We now observe that factored systems are less
sensitive to lexical variations and make more
stable morphological predictions. The differences
with the entropy values computed for the phrase-based
systems are spectacular, especially for verbal
morphology. We understand this poor performance
for phrase-based systems as a consequence of the
initial assumption those systems rely on: the 
concatenation of phrases to constitute an output
sentence does not help to provide a single morphological
prediction in slightly various contexts.

As an attempt to evaluate the error margin of our evaluation results,
we have run a manual check of our evaluation measures.
For this, we have taken all 500 sentence pairs reflecting past
tense (A-set), as well as case (pronouns to nouns in B-set), and took translations from different
systems randomly. We report on cases where the modification of the source created
a ``bad'' (meaningless or ungrammatical) variant,
as well as sample translations erroneously considered
successful or unsuccessful. For past tense, we observe a low
quantity of false positive (1.6\%) and false negative (0.4\%). The
ratio of bad sources is quite low as well (3\%), and is
mostly related to cases where a word was given the wrong
analysis in the first place, such as a noun labeled
by the PoS-tagger as a verb, which was then turned
into a past form. For pronouns to nouns, there are
nearly no bad source sentences (0.2\%): the transformation of
pronouns into noun phrases is quite easy and safe.
While false positive labels are lower (0.2\%), there is a higher amount of false
positive (4.4\%), which was mainly due to our word-based
NMT system that generates many unknown words and presents
important differences between base and variant: several
adjectives and nouns, not corresponding to the ones we generated
in the source sentence, could then be considered during the
evaluation.

%% \begin{table*}[tb] %%[!htbp]
%% \begin{center}
%% \scriptsize %small
%% \begin{tabular}{lcc}
%% \multicolumn{3}{c}{\textbf{verbs - past}}\\
%% & Abs. & Rel. \\
%% \hline
%% \textbf{Bad Source} & 15 & 3.0\% \\
%% \textbf{False Positive} & 8 & 1.6\% \\
%% \textbf{False Negative} & 2 & 0.4\% \\
%% \hline
%% \multicolumn{3}{c}{\textbf{pronouns to noun - case}}\\
%% & Abs. & Rel. \\
%% \hline
%% \textbf{Bad Source} & 1 & 0.2\% \\
%% \textbf{False Positive} & 22 & 4.4\% \\
%% \textbf{False Negative} & 1 & 0.2\% \\
%% \hline
%%  \end{tabular} 
%% \caption{\label{table:eval_err} Evaluation errors, samples from sets A and B.}
%% \end{center}
%% \end{table*}


For English-to-Latvian, we have represented
the same types of systems as for Czech, with an additional hybrid
system. The scores and morphological accuracies of the systems submitted at WMT'17 are in Table~\ref{tab:bleuLv}.

\begin{itemize}
  \item Phrase-based systems: The \textbf{Moses baseline} was trained on
    WMT'17 data and \textbf{TILDE PBMT}
    was provided by TILDE\footnote{\url{http://www.tilde.com/mt}} and is described in \cite{peter17qt21}.
    These systems did not take part in the official WMT'17 evaluation campaign.
  \item Word-based NMT: \textbf{NMT words} is a system trained on
    WMT'17 parallel data with a 80K target vocabulary. It
    was not submitted at WMT'17 and is used here as a contrast.
  \item BPE-based NMT: \textbf{LIMSI NMT} \cite{burlot16wmt} is based on NMTPY and
    \textbf{UEDIN NMT} \cite{uedin2017wmt} on Nematus.
  \item NMT modeling target morphology: \textbf{LIMSI FNMT} \cite{burlot16wmt} and
    \textbf{LIUM FNMT} \cite{garcia2017wmtnews} use a factored output predicting words and PoS.
  \item Hybrid system: \textbf{TILDE hybrid} is an ensemble of NMT models
    using a PBMT to process rare and unknown words. It was
    submitted at WMT'17 \cite{Pinnis2017}.
\end{itemize}

\begin{table*} %%[tb] %%[!htbp]
\begin{minipage}{.40\linewidth}
\begin{center}
\scriptsize %small
\begin{tabular}{ l|cccc } 
\hline
System & BLEU $\uparrow$ & BEER $\uparrow$ & CTER $\downarrow$ & Acc. \\
\hline
\textbf{LIMSI NMT}      & 15.91 & 52.91 & 61.56 & 85.36 \\
\textbf{UEDIN NMT}      & 17.20 & 53.77 & 65.60 & 85.99 \\
\textbf{LIMSI FNMT}     & 16.93 & 53.73 & 60.57 & 85.57 \\
\textbf{LIUM FNTM}      & 16.13 & 52.81 & 61.90 & 84.05 \\
\textbf{TILDE hybrid}   & 20.28 & 55.46 & 57.46 & 87.95 \\
\hline
\end{tabular} 
\caption{\label{tab:bleuLv} Scores of the English-to-Latvian WMT'17 submissions on the official test set.}
\end{center}
\end{minipage}
\hspace{7mm}
\begin{minipage}{.55\linewidth}
\begin{center}
\scriptsize %%small
\begin{tabular}{ l|cc|cc|c||c }
\hline
& \multicolumn{2}{c}{\textbf{verbs}} & \multicolumn{2}{c}{\textbf{pronouns}} & \multicolumn{1}{c}{\textbf{nouns}}  & \multicolumn{1}{c}{\textbf{mean}} \\
\hline
System & past & future & fem. & plur. & number & \\
\hline
\textbf{Moses baseline} & 67.0\% & 83.2\% & 68.6\% & 83.6\% & 63.6\% & 73.2\% \\
\textbf{TILDE PBMT}     & 68.8\% & 70.4\% & 56.0\% & 71.8\% & 65.0\% & 66.4\% \\
\textbf{NMT words}      & 56.8\% & 64.0\% & 38.6\% & 71.4\% &  59.2\% & 58.0\%\\
\textbf{UEDIN NMT}      & 74.6\% & 83.6\% & 57.0\% & 88.6\% & 69.4\% & 74.6\% \\
\textbf{LIMSI NMT}      & 68.8\% & 84.6\% & 64.2\% & 86.8\% & 73.0\% & 75.5\% \\
\textbf{LIMSI FNMT}     & 69.6\% & 82.8\% & 62.0\% & \textbf{89.0\%} & 70.6\% & 74.8\% \\
\textbf{LIUM FNMT}      & 73.0\% & 81.2\% & \textbf{76.8\%} & 86.6\% & \textbf{73.2\%} & \textbf{78.2\%} \\
\textbf{TILDE hybrid}   & \textbf{79.6\%} & \textbf{92.0\%} & 49.4\% & 87.2\% & 71.2\% & 75.9\% \\
\hline
 \end{tabular} 
\caption{\label{table:eval_lv_A} Sentence pair evaluation for English-to-Latvian (A-set).}
\end{center}
\end{minipage}
\end{table*}


\begin{table*}[tb] %%[!htbp]
\begin{center}
\small
\begin{tabular}{ l|ccc|c|ccc|c||c }
\hline
& \multicolumn{3}{c}{\textbf{coordinated verbs}} & \multicolumn{1}{c}{\textbf{coord.n}} & \multicolumn{3}{c}{\textbf{pronouns to nouns}} & \multicolumn{1}{c}{\textbf{prep.}}  & \multicolumn{1}{c}{\textbf{mean}} \\
\hline
System & number & person & tense & case & gender & number & case & case & \\
\hline
\textbf{Moses baseline} & 50.2\% & 37.4\% & 50.6\% & 42.2\% & 21.4\% & 24.0\% & 14.8\% & 45.1\% & 35.7\% \\
\textbf{TILDE PBMT}     & 49.6\% & 32.8\% & 50.2\% & \textbf{47.6\%} & 24.0\% & 25.4\% & 19.0\% & 48.5\% & 37.1\% \\
\textbf{NMT words}      & 43.0\% & 36.0\% & 43.6\% & 15.6\% &  7.8\% &  8.0\% &  7.8\% & 44.1\% & 25.7\% \\
\textbf{UEDIN NMT}      & 70.6\% & 60.8\% & 72.0\% & 30.2\% & 46.4\% & 44.8\% & 43.4\% & 56.7\% & 53.1\% \\
\textbf{LIMSI NMT}      & 69.2\% & 57.6\% & 70.4\% & 41.8\% & 40.0\% & 40.8\% & 35.8\% & 54.6\% & 51.3\% \\ 
\textbf{LIMSI FNMT}     & 72.4\% & 63.4\% & 73.2\% & 34.8\% & 43.0\% & 42.2\% & 41.4\% & 55.5\% & 53.2\% \\
\textbf{LIUM FNMT}      & \textbf{78.0\%} & \textbf{67.0\%} & \textbf{78.6\%} & 37.2\% & 38.6\% & 38.0\% & 35.6\% & 56.1\% & 53.6\% \\
\textbf{TILDE hybrid}   & 69.0\% & 61.8\% & 69.4\% & 35.4\% & \textbf{54.6\%} & \textbf{53.0\%} & \textbf{53.2\%} & \textbf{58.3\%} & \textbf{56.8\%} \\
\hline
 \end{tabular} 
\caption{\label{table:eval_lv_B} Sentence pair evaluation for English-to-Latvian (B-set).}
\end{center}
\end{table*}


The results for the A-set evaluation are in Table~\ref{table:eval_lv_A}.
Compared to the previous Czech evaluation, there is a less clear difference
between phrase-based and NMT systems based on BPE. Indeed, TILDE hybrid has
the best mean performance and is only 5 points above our Moses
baseline. A possible reason for that situation is the lower
amount of parallel data available for English-Latvian,
compared to English-Czech.
We notice that there is no significant difference between the two
NMT systems and LIMSI FNMT.
With this language pair, word-based
NMT performs significantly worse than all other systems on all morphological
features, which is confirmed by the fluency evaluation in Table~\ref{table:eval_lv_B}.
Here, the factored systems tend to have a better verbal fluency, whereas
NMT systems perform better on nominal agreement: LIMSI FNMT has the best mean score,
but is only 0.2 points above UEDIN NMT. The best system, TILDE hybrid, is
now 21.1 points above the Moses baseline, which again seems to be the main
reason for such high overall morphological accuracy in Table~\ref{tab:bleuLv}.

\begin{table*}[tb] %%[!htbp]
\begin{center}
\small
\begin{tabular}{ l|c|ccc|ccc||c } 
\hline
& \multicolumn{1}{c}{\textbf{nouns}} & \multicolumn{3}{c}{\textbf{adjectives}} & \multicolumn{3}{c}{\textbf{verbs}} & \multicolumn{1}{c}{\textbf{mean}} \\
\hline
System & case & gender & number & case & number & person & tense & \\
\hline
\textbf{Moses baseline} & .467 & .738 & .717 & .753 & .271 & .352 & .285 & .512 \\ 
\textbf{TILDE PBMT}     & .436 & .755 & .735 & .768 & .254 & .337 & .258 & .506 \\
\textbf{NMT words}      & .385 & .751 & .732 & .764 & .329 & .353 & .337 & .522 \\ 
\textbf{UEDIN NMT}      & .234 & .598 & .596 & .628 & .115 & .190 & .114 & .354 \\ 
\textbf{LIMSI NMT}      & .255 & .616 & .610 & .644 & .139 & .221 & .134 & .374 \\ 
\textbf{LIMSI FNMT}     & .233 & \textbf{.587} & .582 & .612 & .117 & .182 & .113 & .346 \\
\textbf{LIUM FNMT}      & .213 & .608 & .606 & .643 & .099 & .163 & .092 & .346 \\ 
\textbf{TILDE hybrid}   & \textbf{.198} & \textbf{.587} & \textbf{.581} & \textbf{.608} & \textbf{.088} & \textbf{.123} & \textbf{.090} & \textbf{.325} \\ 
\hline
 \end{tabular} 
\caption{\label{table:eval_lv_C} Sentence group evaluation for English-to-Latvian with Entropy (C-set).}
\end{center}
\end{table*}

Table~\ref{table:eval_lv_C} confirms the higher performance
of NMT and factored NMT systems, with a clear advantage for TILDE hybrid,
which has the best accuracy in terms of fluency, like in the previous Table~\ref{table:eval_lv_B},
which tends to show some correlation between both
types of tests.

When it comes to morphological correction of the output,
our evaluation clearly shows the superiority of BPE-based
NMT systems over phrase-based ones. On the other hand, while we observed
that factored models obtain a higher performance in terms of
adequacy, NMT models are still very close to them in terms
of fluency. Finally, factored models, as well as TILDE hybrid, clearly showed more
confidence in their predictions through slight lexical variations.


\section{Related work: evaluating morphology \label{sec:related}}

\paragraph{Automatic metrics}
Despite their well-known flaws, ``general purpose'' automatic metrics such as BLEU \citep{Papineni02bleu}, TER \citep{Snover06study} or METEOR \citep{Banerjee05meteor} remain the preferred way to measure progress in Machine Translation. Evaluation campaigns aimed at comparing systems have long abandoned these measures and resort to human judgments, such as ranking \cite{Callisonburch07meta} or direct assessment \citep{Bojar16findings}. To compensate for the inability of eg.~BLEU to detect improvements targeting specific difficulties of MT, several problem-specific measures have been introduced over the years such as the LR-Score \citep{Birch10lrscore} to measure the correctness of reordering decisions, MEANT \citep{Lo11meant} to measure the transfer of entailment relationships, or CharacTER \citep{Wang16character} to better assess the success of translation into a MRL. 
\citet{Stanojevic14beer}'s BEER is a nice example of a sophisticated metric, based on a trainable mixture of multiple metrics: for MRLs, the inclusion of character n-gram matches and of reordering scores proves critical to reach good correlation with human judgments. In comparison, the proposal of \citet{Wang16character} simply computes a TER-like score at the character level, thereby partially crediting a system for predicting the right lemma with the wrong morphology.

\paragraph{Error typologies}
% Error typologies in MT -Flanagan,  1994;Vilar  et  al.,  2006;  Farrus  Cabeceran  et  al.,  2010; Stymne and Ahrenberg, 2012; Lommel et al., 2014).
Error analysis protocols, as proposed by \citet{Vilar06error,Popovic11towards,Stymne11blast} for PBMT systems are obvious candidates for running diagnosis studies and have been used eg.\ by \citet{Bentivogli16neural,Toral17multifacet,Costajussa17whycatalan,Kublicka17finegrained}. These works differ in the language pairs and in the error typology considered. \citet{Bentivogli16neural} only recognizes three main error types which are automatically recognized based on aligning the hypotheses and references -- for instance a morphological error is detected when the word form is wrong, whereas the lemma is correct; this definition is also adopted in \citep{Toral17multifacet}, and decomposed at the level of morphological features in \citep{Peter16qt21}; \citep{Kublicka17finegrained} use a more detailed typology derived from the MQM proposal\footnote{\url{http://www.qt21.eu/mqm-definition}} and adapted to the English:Croatian pair -- morphological errors mostly correspond to ``word form'' errors and are too subtle to be automatically detected. 
A common finding of these studies is that NMT generates better agreements than alternatives such as PBMT or Hierarchical MT.

\paragraph{Test suites}
The work of \citet{Isabelle17challenge,Burchardt17linguistic} resuscitates an old tradition of using carefully designed test suites \citet{King90using,Lehmann96tsnlp} to explore the ability of NMT to handle specific classes of difficulties. Test suites typically include a small set of  handcrafted sentences for each targeted type of difficulty. For instance,  \citet{Isabelle17challenge} focuses on translating from English into French and is based on a set of 108 short sentences illustrating situations of morpho-syntactic, lexico-syntactic and syntactical divergences between these two languages. Assessing a system's ability to handle these difficulties requires a human judge to decide whether the automated translation has successfully ``crossed'' the bridge between languages.\footnote{Note that this is a \emph{local} evaluation -- a system can produce a bad overall translation, yet pass the test.}
A similar methodology is used in the work of \citet{Burchardt17linguistic}, who use a test suite of approximately 800 segments covering a wide array of translation difficulties for the pair English-German. Test suites enable to directly evaluate and compare specific
abilities of MT Engines, including morphological competences: again,  both studies found that NMT is markedly better than PBMT when it comes to phenomena such as word agreement. The downside is the requirement to have expert linguists prepare the data as well as evaluate the success of the MT system, which is a rather expensive price to pay to get a diagnostic evaluation. 

\paragraph{Automatic test suites}
The work by \citet{Linzen16assessing} specifically looks at the prediction of the correct agreement features in increasingly complex contexts generated by augmenting the distance between the head and its dependent and the number of intervening distractors. A language model is deemed correct if it scores the correct agreement higher than any wrong one. One intriguing finding of this study is the very good performance of RNNs, provided that they receive the right kind of feedback in training. 
A similar approach is adapted for MT by \citet{Sennrich17howgrammatical}, who looks at a wider range of phenomena. Contrastive pairs as automatically produced as follows: given a correct (source, target) pair $p=(\src,\trg)$, introduce one error in $\trg $ yielding an alternative couple $p'=(\src,\trg')$. A system is deemed to perform correctly wrt.\ this contrastive pair %% if it gives a higher score to the correct target sentence.
%formed by a colocally perturb correct sentence pairs and then check model is deemed to make the right decisions
if it scores $p$ higher than $p'$. This approach is fully automatic, looks at a wide range of contexts and phenomena and also enables to focus on specific errors types; a downside is the fact that the evaluation never considers whether $\trg$ is the system's best choice given source $\src$. Regarding specifically morphology, this study mostly considers (subject-verb, as well as modifier-head noun) agreement errors, but only compares error rates of variants of NMT systems.

\paragraph{A typology of evaluation protocols}

The variety of evaluation protocols found in the literature can be categorized along the following dimensions:
\begin{itemize}
\item \emph{holistic} vs \emph{analytic}: a holistic metric provides a global sentence- or document-level score, of which the morphological ability is only one part; an analytic metric focuses on specific difficulties;
\item \emph{coarse} vs \emph{fine-grain}: a coarse (analytic) metric only provides global appreciation of morphological competence; while a fine-grain metric distinguishes various types of errors;
\item \emph{natural} vs \emph{hand-crafted} vs \emph{artificial}: for the sake of this study, this distinction relates to the design of the test sentences -- were they invented for the purpose of the evaluation or found in a corpus, or even generated using automatic processing~?
\item \emph{automatic} vs \emph{human-judgment}: is scoring fully automatic or is a human judge involved~?
\item scores can be distance-based, such as a global comparison with a reference translation, or a Boolean value that denotes success or failure wrt.\ a local test, or based on a comparison of model scores;
\end{itemize}

Based on this analysis, the work reported here is analytic/fine-grain, uses artificial data, and computes automatic scores based on a local comparison with an expected value (mostly). This is the only one of that kind we are aware of.
% Table~\ref{tab:metrics} 
% \begin{table}
% \begin{tabular}{lll}
% method & &
% error 
% source alternations &
% target contrast &
% auxiliary tasks

% test set:
% random  &
% artificial  &
% hand-design &

% success : & human judges / automatic
% \end{tabular}
% \end{table}

\section{Conclusion and Outlook \label{sec:conclusion}}

In this paper, we have presented a new protocol for evaluating the morphological competence of a Machine Translation system, with the aim to measure progresses in handling complex morphological phenomena in the source or the target language. We have presented preliminary experiments for two language pairs, which show that NMT systems with BPE outperform in many ways the phrase-based MT systems. Interestingly, they also reveal subtle differences among NMT systems and indicate specific areas where improvements are still needed.
This work will be developed in three main directions: 
\begin{itemize}
\item improve the generation and scoring algorithms: our procedure for generating sentences relies on automatic morphological analysis, which can be error prone, and on crude heuristics. While these two sources of noise likely have a small impact on the final results, which represent an average over a large number of sentences, we would like to better evaluate these effects, and, if needed, apply the necessary fixes;
\item refine our analysis of automatic scores: the numbers reported in \textsection~\ref{sec:experiments} are averages over multiple sentences, and could be subjected to more analyses such as looking more precisely at OOVs, or taking frequency effects in considerations. This would allow to assess a system's ability to generate the right form for frequent vs rare vs unseen lemmas or morphological features.
% It would indeed be interesting to look at the performance with respect to the frequency of a given test form or lemma in the training set: arguably, morphological competence is not just about using the right form but also requires the ability to derive the right translation even for unknown words. 
Frequency is also often correlated with regularity, and we also would like to assess morphological competence along those lines. Likewise, analyzing performance in agreement tests with respect to the distance between two coordinated nouns or verbs might also be revealing.
\item increase the set of tests: we have focused on translating English into two MRLs having similar properties. Future work includes the generation of additional inflectional contrasts (introducing for instance mood or aspect, which are morphologically marked in many languages) as well as derivational contrasts (such as diminutives for nouns, or antonyms for adjectives). Again, this implies to improve our scoring and generation algorithms, and to adapt them to new languages. 
\end{itemize}
\section*{Acknowledgements}
The authors thank the participants to the WMT'17 News Translation task who kindly translated our test sets into Latvian and Czech.
This work has been partly funded by the European Union‚Äôs
Horizon 2020 research and innovation programme under grant
agreement No.~645452 (QT21).

\bibliographystyle{emnlp_natbib}
\bibliography{havewegotbetter}


%% \newpage{}
%% \appendix

%% \onecolumn

%% \section{Samples from the test suite}
%% \label{append:samples}

%% \begin{table}[h!] %%[!htbp]
%% \begin{center}
%% \scriptsize %%small
%% \begin{tabular}{ l } 
%% \hline
%% \multicolumn{1}{c}{\textbf{number (nouns)}} \\
%% \hline
%% The Free Press did not explain exactly how it obtained the message. \\
%% The Free Press did not explain exactly how it obtained the messages. \\
%% After a tour of Gaza, Holmes urged a reopening of the border. \\
%% After a tour of Gaza, Holmes urged a reopening of the borders. \\
%% Gross margins remained consistent during this period. \\
%% Gross margins remained consistent during these periods. \\
%% That was a very good development for the Viking. \\
%% That was a very good development for the Vikings. \\
%% In the US, recessionary fears also hit the market. \\
%% In the US, recessionary fears also hit the markets. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{number (pronouns)}} \\
%% \hline
%% She said she's going to pray for him. \\
%% She said she's going to pray for them. \\
%% Then, I heard him yell my name. " \\
%% Then, I heard them yell my name. " \\
%% The Celtics had plenty of offensive punch without him. \\
%% The Celtics had plenty of offensive punch without them. \\
%% I saw him as someone who enjoyed life. \\
%% I saw them as someone who enjoyed life. \\
%% The union has endorsed him. \\
%% The union has endorsed them. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{gender (pronouns)}} \\
%% \hline
%% They told him not to worry. \\
%% They told her not to worry. \\
%% It's not inertia that is holding him back, though. \\
%% It's not inertia that is holding her back, though. \\
%% We just built a case for him one meet at a time. " \\
%% We just built a case for her one meet at a time. " \\
%% You can't wait to see him again after school starts. \\
%% You can't wait to see her again after school starts. \\
%% President Bush awarded him the Presidential Medal of Freedom in 2004. \\
%% President Bush awarded her the Presidential Medal of Freedom in 2004. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{tense:future}} \\
%% \hline
%% That's verging so close to moralism that it quite cheers me up. \\
%% That's verging so close to moralism that it will quite cheer me up. \\
%% Security Council bans trade in goods that have both civilian, military use \\
%% Security Council will ban trade in goods that have both civilian, military use \\
%% Everyone wants to be in Iraq, your own country is best. \\
%% Everyone will want to be in Iraq, your own country is best. \\
%% He denies this, saying the girl was killed in the crossfire. \\
%% He will deny this, saying the girl was killed in the crossfire. \\
%% Premature birth remains a prime cause of infant death in industrialized countries. \\
%% Premature birth will remain a prime cause of infant death in industrialized countries. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{tense:past}} \\
%% \hline
%% Some even include warnings to would-be jumpers. \\
%% Some even included warnings to would-be jumpers. \\
%% That's what I want. ‚Äù \\
%% That's what I wanted. ‚Äù \\
%% So whatever they decide. ‚Äù \\
%% So whatever they decided. ‚Äù \\
%% The narrow openings provide a hospitable place for the bats to hang. \\
%% The narrow openings provided a hospitable place for the bats to hang. \\
%% Oil prices extend falls on US demand concerns, dollar rebound \\
%% Oil prices extended falls on US demand concerns, dollar rebound \\
%% \hline
%% \multicolumn{1}{c}{\textbf{comparative}} \\
%% \hline
%% The improved science will allow real-time monitoring of HIV infections. \\
%% The improved science will allow more real-time monitoring of HIV infections.\\
%% I promise you that soon you will be old. ‚Äù\\
%% I promise you that soon you will be older. ‚Äù\\
%% The terror network has been growing sophisticated in targeting international audiences.\\
%% The terror network has been growing more sophisticated in targeting international audiences.\\
%% Who is likely to order a drink straight up?\\
%% Who is more likely to order a drink straight up?\\
%% I can give you a long answer....\\
%% I can give you a longer answer....\\
%% \hline
%% \multicolumn{1}{c}{\textbf{polarity (verbs)}} \\
%% \hline
%% The road will reopen on Friday morning. \\
%% The road will not reopen on Friday morning. \\
%% As in previous seasons, both finalists will release albums. \\
%% As in previous seasons, both finalists will not release albums. \\
%% Asked to define what Kentucky fans expect from their team, Stevenson said. \\
%% Asked to define what Kentucky fans do not expect from their team, Stevenson said. \\
%% ‚ÄúActually, I really recommend it, ‚Äù she said. \\
%% ‚ÄúActually, I do not really recommend it, ‚Äù she said. \\
%% "We have just got to be more clinical in the final third. \\
%% "We have not just got to be more clinical in the final third. \\
%% \hline
%% \end{tabular}
%% \caption{\label{tab:A1} Samples from the A-set.}
%% \end{center}
%% \end{table}

%% \begin{table*}[tb] %%[!htbp]
%% \begin{center}
%% \small
%% \begin{tabular}{ l } 
%% \hline
%% \multicolumn{1}{c}{\textbf{complex NP}} \\
%% \hline
%% What she fears is not being able to breathe. \\
%% What the magical midwife fears is not being able to breathe. \\
%% James said he takes pride in doing it all. \\
%% James said the comfortable shoemaker takes pride in doing it all. \\
%% Look, you all figured that out. \\
%% Look, the diffident hunters all figured that out. \\
%% But she and her husband, Paul, gave little thought to termination. \\
%% But the unnerved watchman and her husband, Paul, gave little thought to termination. \\
%% "I'm not a very athletic person," he said. \\
%% "I'm not a very athletic person," the explosive potter said. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{coordinated NP}} \\
%% \hline
%% When you execute, you generally win. \\
%% When the appraiser and the resilient gate-keeper execute, you generally win. \\
%% Sometimes you need to just let things fall into place. ‚Äù \\
%% Sometimes the engineer and the charming clergymen need to just let things fall into place. ‚Äù \\
%% First, we need more disclosure and accountability in the housing market. \\
%% First, the priest and the slightly resilient shoemakers need more disclosure and accountability in the housing market. \\
%% Frei: Mr President, I gather we've run out of time. \\
%% Frei: Mr President, I gather the draughtsmen and the worthy waiters've run out of time. \\
%% But until we are sent screaming from the room, we are bored. \\
%% But until the policemen and the waspish poets are sent screaming from the room, we are bored. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{coordinated verbs}} \\
%% \hline
%% The governor often jokes about political disagreements with his wife. \\
%% The governor often jests and jokes about political disagreements with his wife. \\
%% Lindsay picks up the story. \\
%% Lindsay culls and, as usual, picks up the story. \\
%% The National Press Club dinner will begin promptly at 6: 30 p.m. \\
%% The National Press Club dinner will get and really begin promptly at 6: 30 p.m. \\
%% Fox plans a spinoff of "Family Guy." \\
%% Fox projects and plans a spinoff of "Family Guy." \\
%% The hero, Tim, offends just about everybody while remaining totally deadpan. \\
%% The hero, Tim, outrages and actually offends just about everybody while remaining totally deadpan. \\
%% \hline
%% \end{tabular}
%% \caption{\label{tab:B} Samples from the B-set.}
%% \end{center}
%% \end{table*}


%% \begin{table*}[tb] %%[!htbp]
%% \begin{center}
%% \small
%% \begin{tabular}{ l } 
%% \hline
%% \multicolumn{1}{c}{\textbf{prep-case:during-before}} \\
%% \hline
%% "I noticed he was feeling it (during the weekend)." \\
%% "I noticed he was feeling it (before the weekend)." \\
%% It wasn't known whether he was present during the raid. \\
%% It wasn't known whether he was present before the raid. \\
%% Some learned through cell phone calls during class. \\
%% Some learned through cell phone calls before class. \\
%% Bryant scored nine points during the spurt. \\
%% Bryant scored nine points before the spurt. \\
%% He was visited during the celebration by team president J.D. Gibbs. \\
%% He was visited before the celebration by team president J.D. Gibbs. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{prep-case:underneath-on-top-of}} \\
%% \hline
%% "I just lost it there underneath Tony," Harvick said. \\
%% "I just lost it there on top of Tony," Harvick said. \\
%% It came to a stop underneath the rail line. \\
%% It came to a stop on top of the rail line. \\
%% And he watches the osprey nesting underneath the bridge each spring. \\
%% And he watches the osprey nesting on top of the bridge each spring. \\
%% She threw herself underneath the tractor. \\
%% She threw herself on top of the tractor. \\
%% ‚ÄúThere are many tunnels underneath London. \\
%% ‚ÄúThere are many tunnels on top of London. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{prep-case:inside-outside}} \\
%% \hline
%% He added: "Officers found substantial damage inside the house. \\
%% He added: "Officers found substantial damage outside the house. \\
%% At first, the entire campus was inside a YMCA building. \\
%% At first, the entire campus was outside a YMCA building. \\
%% The male and middle-aged female bodies were found inside the closet-type space. \\
%% The male and middle-aged female bodies were found outside the closet-type space. \\
%% There is an egg inside the tummy and it cracks. \\
%% There is an egg outside the tummy and it cracks. \\
%% Inside the car, you're surrounded by a closed metal circuit. \\
%% Outside the car, you're surrounded by a closed metal circuit. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{prep-case:beside-behind}} \\
%% \hline
%% Some are trying to dry unhusked rice beside the road. \\
%% Some are trying to dry unhusked rice behind the road. \\
%% But that is almost beside the point. \\
%% But that is almost behind the point. \\
%% "It's like living beside a train track. \\
%% "It's like living behind a train track. \\
%% But such problems pale beside the eruptions since August. \\
%% But such problems pale behind the eruptions since August. \\
%% Apart from all that, the sun is shining brightly beside the Mediterranean. \\
%% Apart from all that, the sun is shining brightly behind the Mediterranean. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{prep-case:with-without}} \\
%% \hline
%% Lebanon has been without a president since November. \\
%% Lebanon has been with a president since November. \\
%% Without Superman, would there have been anything else on this list? \\
%% With Superman, would there have been anything else on this list? \\
%% Neither is willing to give up one delegate without a fight. \\
%% Neither is willing to give up one delegate with a fight. \\
%% But again, GM is headed for bankruptcy without government intervention. \\
%% But again, GM is headed for bankruptcy with government intervention. \\
%% This was like a funeral without the fun. \\
%% This was like a funeral with the fun. \\
%% \hline
%%  \end{tabular} 
%% \caption{\label{tab:A2} Samples from the B-set (Prepositions).}
%% \end{center}
%% \end{table*}



%% \begin{table*}[tb] %%[!htbp]
%% \begin{center}
%% \scriptsize %%\small
%% \begin{tabular}{ l } 
%% \hline
%% \multicolumn{1}{c}{\textbf{adjectives}} \\
%% \hline
%% Each of her seven children married a Vietnamese, all of them poor. \\
%% Each of her seven children married a Vietnamese, all of them rich. \\
%% Each of her seven children married a Vietnamese, all of them inadequate. \\
%% Each of her seven children married a Vietnamese, all of them short. \\
%% Each of her seven children married a Vietnamese, all of them miserable. \\
%% It will discuss reforms of the global financial system to prevent another meltdown. \\
%% It will discuss reforms of the world financial system to prevent another meltdown. \\
%% It will discuss reforms of the worldwide financial system to prevent another meltdown. \\
%% It will discuss reforms of the planetary financial system to prevent another meltdown. \\
%% It will discuss reforms of the spherical financial system to prevent another meltdown. \\
%% He sneaks secret phone calls and messages with Sarah. \\
%% He sneaks private phone calls and messages with Sarah. \\
%% He sneaks mysterious phone calls and messages with Sarah. \\
%% He sneaks confidential phone calls and messages with Sarah. \\
%% He sneaks clandestine phone calls and messages with Sarah. \\
%% "I was not aware he found my gift extremely offensive." \\
%% "I was not unaware he found my gift extremely offensive." \\
%% "I was not cognizant he found my gift extremely offensive." \\
%% "I was not mindful he found my gift extremely offensive." \\
%% "I was not cognisant he found my gift extremely offensive." \\
%% The traces of the former occupants are everywhere. \\
%% The traces of the previous occupants are everywhere. \\
%% The traces of the other occupants are everywhere. \\
%% The traces of the old occupants are everywhere. \\
%% The traces of the early occupants are everywhere. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{nouns}} \\
%% \hline
%% Malkin got up and began skating toward the Penguins' zone. \\
%% Malkin got up and began skating toward the Penguins' region. \\
%% Malkin got up and began skating toward the Penguins' part. \\
%% Malkin got up and began skating toward the Penguins' structure. \\
%% Malkin got up and began skating toward the Penguins' place. \\
%% They should only be investing in things they themselves know a lot about. \\
%% They should only be investing in things they themselves know a mess about. \\
%% They should only be investing in things they themselves know a deal about. \\
%% They should only be investing in things they themselves know a mountain about. \\
%% They should only be investing in things they themselves know a plenty about. \\
%% Banks near bankruptcy on Friday night have to be rescued by Sunday. \\
%% Banks near failure on Friday night have to be rescued by Sunday. \\
%% Banks near insolvency on Friday night have to be rescued by Sunday. \\
%% Banks near proceedings on Friday night have to be rescued by Sunday. \\
%% Banks near proceeding on Friday night have to be rescued by Sunday. \\
%% The Times said he is survived by his daughter Bethany and a sister. \\
%% The Times said he is survived by his daughter Bethany and a baby. \\
%% The Times said he is survived by his daughter Bethany and a girl. \\
%% The Times said he is survived by his daughter Bethany and a brother. \\
%% The Times said he is survived by his daughter Bethany and a miss. \\
%% Fenty said he hopes the kiosks will make another qualitative difference. \\
%% Fenty said he hopes the kiosks will make another qualitative change. \\
%% Fenty said he hopes the kiosks will make another qualitative variation. \\
%% Fenty said he hopes the kiosks will make another qualitative departure. \\
%% Fenty said he hopes the kiosks will make another qualitative quality. \\
%% \hline
%% \multicolumn{1}{c}{\textbf{verbs}} \\
%% \hline
%% You notice it everywhere in China. \\
%% You find it everywhere in China. \\
%% You mention it everywhere in China. \\
%% You acknowledge it everywhere in China. \\
%% You ignore it everywhere in China. \\
%% ‚ÄúThat is why he sometimes does not get immediate results. \\
%% ‚ÄúThat is why he sometimes does not produce immediate results. \\
%% ‚ÄúThat is why he sometimes does not bring immediate results. \\
%% ‚ÄúThat is why he sometimes does not mean immediate results. \\
%% ‚ÄúThat is why he sometimes does not generate immediate results. \\
%% The city's Broad Street was shut on Sunday morning, officers said. \\
%% The city's Broad Street was shut on Sunday morning, officers ordered. \\
%% The city's Broad Street was shut on Sunday morning, officers alleged. \\
%% The city's Broad Street was shut on Sunday morning, officers showed. \\
%% The city's Broad Street was shut on Sunday morning, officers requested. \\
%% The men stop to listen. \\
%% The men start to listen. \\
%% The men begin to listen. \\
%% The men continue to listen. \\
%% The men finish to listen. \\
%% The firing was first reported by the Washington Post on its Web site. \\
%% The firing was first described by the Washington Post on its Web site. \\
%% The firing was first announced by the Washington Post on its Web site. \\
%% The firing was first covered by the Washington Post on its Web site. \\
%% The firing was first informed by the Washington Post on its Web site. \\
%% \hline
%% \end{tabular}
%% \caption{\label{tab:C} Samples from the C-set.}
%% \end{center}
%% \end{table*}




\end{document}










\subsection{Morphology in the source}
- Process unknown word forms
-- compounds [take a simple form, replace by a complex form]
--- tests: 
---- S generates a valid T sentence with T words
---- adequacy ?

-- derivatives
--- should not change the semantics too much (attenuative, diminutives)
--- contrastive pairs

-- inflections
-- generates unseen inflection 

\subsection{Morphology in the  target}

\section{Methods}

\subsection{Scoring}
The main idea behind  the \scoring{} technique is to ground the evaluation of a system based on the scores it assigns to pairs of contrastive sentences modify a perfectly valid target $t$ into $t'$ - model score of $t$ higher that $t'$

{document}
