SubmissionNumber#=%=#34
FinalPaperTitle#=%=#CUNI System for the WMT17 Multimodal Translation Task
ShortPaperTitle#=%=#CUNI System for the WMT17 Multimodal Translation Task
NumberOfPages#=%=#8
CopyrightSigned#=%=#Jindřich Helcl
JobTitle#==#
Organization#==#Charles University
Faculty of Mathematics and Physics
Malostranské náměstí 25
11800 Prague
Czech Republic
Abstract#==#In this paper, we describe our submissions to the WMT17 Multimodal Translation
Task. 
For Task 1 (image caption translation), our best scoring system is a purely
textual neural translation  of the source image caption to the target language.
The main feature of the system is the use of additional data that was acquired
by selecting similar sentences from parallel corpora and by data synthesis by
back-translation.
For Task 2 (captioning in a less-resourced language), our best submitted system
generates an English caption which is then translated by the best system used
in Task 1.
We also present negative results, which are based on ideas that we believe have
potential of making improvements, but did not prove to be useful in our
particular setup.
Author{1}{Firstname}#=%=#Jindřich
Author{1}{Lastname}#=%=#Helcl
Author{1}{Email}#=%=#helcl@ufal.mff.cuni.cz
Author{1}{Affiliation}#=%=#Charles University in Prague
Author{2}{Firstname}#=%=#Jindřich
Author{2}{Lastname}#=%=#Libovický
Author{2}{Email}#=%=#libovicky@ufal.mff.cuni.cz
Author{2}{Affiliation}#=%=#Charles University in Prague

==========