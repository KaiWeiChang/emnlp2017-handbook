SubmissionNumber#=%=#10
FinalPaperTitle#=%=#Shortcut-Stacked Sentence Encoders for Multi-Domain Inference
ShortPaperTitle#=%=#Shortcut-Stacked Sentence Encoders for Multi-Domain Inference
NumberOfPages#=%=#5
CopyrightSigned#=%=#Mohit Bansal
JobTitle#==#
Organization#==#UNC Chapel Hill
Abstract#==#We present a simple sequential sentence encoder for multi-domain natural
language inference. Our encoder is based on stacked bidirectional LSTM-RNNs
with shortcut connections and fine-tuning of word embeddings. The overall
supervised model uses the above encoder to encode two input sentences into two
vectors, and then uses a classifier over the vector combination to label the
relationship between these two sentences as that of entailment, contradiction,
or neural. Our Shortcut-Stacked sentence encoders achieve strong improvements
over existing encoders on matched and mismatched multi-domain natural language
inference (top single-model result in the EMNLP RepEval 2017 Shared Task
(Nangia et al., 2017)). Moreover, they achieve the new state-of-the-art
encoding result on the original SNLI dataset (Bowman et al., 2015).
Author{1}{Firstname}#=%=#Yixin
Author{1}{Lastname}#=%=#Nie
Author{1}{Email}#=%=#nyixin318@gmail.com
Author{1}{Affiliation}#=%=#UNC
Author{2}{Firstname}#=%=#Mohit
Author{2}{Lastname}#=%=#Bansal
Author{2}{Email}#=%=#mbansal@cs.unc.edu
Author{2}{Affiliation}#=%=#University of North Carolina at Chapel Hill

==========