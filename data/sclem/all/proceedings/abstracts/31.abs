Recently, there has been increased interest in utilizing characters or subwords
	for natural language processing (NLP) tasks. However, the effect of utilizing
	character, subword, and word-level information simultaneously has not been
	examined so far. In this paper, we propose a model to leverage various levels
	of input features to improve on the performance of an supersense tagging task.
	Detailed analysis of experimental results show that different levels of input
	representation offer distinct characteristics that explain performance
	discrepancy among different tasks.