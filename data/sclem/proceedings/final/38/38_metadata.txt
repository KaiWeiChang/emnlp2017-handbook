SubmissionNumber#=%=#38
FinalPaperTitle#=%=#Exploring Cross-Lingual Transfer of Morphological Knowledge In Sequence-to-Sequence Models
ShortPaperTitle#=%=#Exploring Cross-Lingual Transfer of Morphological Knowledge In Sequence-to-Sequence Models
NumberOfPages#=%=#6
CopyrightSigned#=%=#Katharina Kann
JobTitle#==#PhD student/researcher
Organization#==#LMU
Oettingenstra√üe 67
80538 Munich
Germany
Abstract#==#Multi-task training is an effective method to mitigate the data sparsity
problem. 
It has recently been applied for cross-lingual transfer learning for paradigm
completion---the task of producing inflected forms of lemmata---with
sequence-to-sequence networks.
However, it is still vague how the model transfers knowledge across languages,
as well as if and which information is shared.
To investigate this, we propose a set of data-dependent experiments using an
existing 
encoder-decoder recurrent neural network for the task. Our results show that 
indeed the performance gains surpass a pure regularization effect and that
knowledge about language and 
morphology can be transferred.
Author{1}{Firstname}#=%=#Huiming
Author{1}{Lastname}#=%=#Jin
Author{1}{Email}#=%=#huiming.jin.buaa@gmail.com
Author{1}{Affiliation}#=%=#Beihang University
Author{2}{Firstname}#=%=#Katharina
Author{2}{Lastname}#=%=#Kann
Author{2}{Email}#=%=#kann@cis.lmu.de
Author{2}{Affiliation}#=%=#LMU Munich

==========