@InProceedings{sharma-parekh-talukdar:0:TOBEFILLED-EduApp,
  author    = {Sharma, Aditya  and  Parekh, Zarana  and  Talukdar, Partha},
  title     = {Speeding up Reinforcement Learning-based Information Extraction Training using Asynchronous Methods},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {2641--2646},
  abstract  = {RLIE-DQN is a recently proposed Reinforcement Learning-based Information
	Extraction (IE) technique which is able to incorporate external evidence during
	the extraction process. RLIE-DQN trains a single agent sequentially, training
	on one instance at a time. This results in significant training slowdown which
	is undesirable. We leverage recent advances in parallel RL training using
	asynchronous methods and propose RLIE-A3C. RLIE-A3C trains multiple agents in
	parallel and is able to achieve upto 6x training speedup over RLIE-DQN, while
	suffering no loss in average accuracy.},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1279, http://www.aclweb.org/anthology/W17-20 0}
}

