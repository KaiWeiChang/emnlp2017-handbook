@InProceedings{wang-EtAl:0:TOBEFILLED-EduApp1,
  author    = {Wang, Kexiang  and  Liu, Tianyu  and  Sui, Zhifang  and  Chang, Baobao},
  title     = {Affinity-Preserving Random Walk for Multi-Document Summarization},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {210--220},
  abstract  = {Multi-document summarization provides users with a short text that summarizes
	the information in a set of related documents. This paper introduces
	affinity-preserving random walk to the summarization task, which preserves the
	affinity relations of sentences by an absorbing random walk model. Meanwhile,
	we put forward adjustable affinity-preserving random walk to enforce the
	diversity constraint of summarization in the random walk process. The ROUGE
	evaluations on DUC 2003 topic-focused summarization task and DUC 2004 generic
	summarization task show the good performance of our method, which has the best
	ROUGE-2 recall among the graph-based ranking methods.
	Author{3}{Affiliation}},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1 20, http://www.aclweb.org/anthology/W17-20 0}
}

