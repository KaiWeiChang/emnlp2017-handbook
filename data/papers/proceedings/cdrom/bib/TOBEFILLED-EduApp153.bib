@InProceedings{nguyen-daumeiii-boydgraber:0:TOBEFILLED-EduApp,
  author    = {Nguyen, Khanh  and  Daum\'{e} III, Hal  and  Boyd-Graber, Jordan},
  title     = {Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {1463--1473},
  abstract  = {Machine translation is a natural candidate
	problem for reinforcement learning from
	human feedback: users provide quick,
	dirty ratings on candidate translations to
	guide a system to improve. Yet, current
	neural machine translation training focuses
	on expensive human-generated reference
	translations. We describe a reinforcement
	learning algorithm that improves
	neural machine translation systems
	from simulated human feedback.
	Our algorithm combines the advantage
	actor-critic algorithm (Mnih et al., 2016)
	with the attention-based neural encoder-decoder
	architecture (Luong et al., 2015).
	This algorithm (a) is well-designed for
	problems with a large action space and
	delayed rewards, (b) effectively optimizes
	traditional corpus-level machine translation
	metrics, and (c) is robust to skewed,
	high-variance, granular feedback modeled
	after actual human behaviors.},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1153, http://www.aclweb.org/anthology/W17-20 0}
}

