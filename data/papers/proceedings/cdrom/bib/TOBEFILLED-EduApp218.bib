@InProceedings{du-cardie:0:TOBEFILLED-EduApp,
  author    = {Du, Xinya  and  Cardie, Claire},
  title     = {Identifying Where to Focus in Reading Comprehension for Neural Question Generation},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {2056--2062},
  abstract  = {A first step in the task of automatically generating questions for testing
	reading comprehension is to identify \emph{question-worthy} sentences, i.e.
	sentences in a text passage that humans find it worthwhile to ask questions
	about. We propose a hierarchical neural sentence-level sequence tagging model
	for this task, which existing approaches to question generation have ignored.
	The approach is fully data-driven — with no sophisticated NLP pipelines or
	any hand-crafted rules/features — and compares favorably to a number of
	baselines when evaluated on the SQuAD data set. When incorporated into an
	existing neural question generation system, the resulting end-to-end system
	achieves state-of-the-art performance for paragraph-level question generation
	for reading comprehension.},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1218, http://www.aclweb.org/anthology/W17-20 0}
}

