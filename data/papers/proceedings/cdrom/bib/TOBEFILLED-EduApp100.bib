@InProceedings{zellers-choi:0:TOBEFILLED-EduApp,
  author    = {Zellers, Rowan  and  Choi, Yejin},
  title     = {Zero-Shot Activity Recognition with Verb Attribute Induction},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {955--967},
  abstract  = {In this paper, we investigate large-scale zero-shot activity recognition by
	modeling the visual and linguistic attributes of action verbs. For example, the
	verb ``salute'' has several properties, such as being a light movement, a
	social act, and short in duration. We use these attributes as the internal
	mapping between visual and textual representations to reason about a previously
	unseen action. In contrast to much prior work that assumes access to gold
	standard attributes for zero-shot classes and focuses primarily on object
	attributes, our model uniquely learns to infer action attributes from
	dictionary definitions and distributed word representations. Experimental
	results confirm that action attributes inferred from language can provide a
	predictive signal for zero-shot prediction of previously unseen activities.},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1100, http://www.aclweb.org/anthology/W17-20 0}
}

