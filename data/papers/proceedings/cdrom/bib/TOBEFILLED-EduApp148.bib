@InProceedings{vanderwees-bisazza-monz:0:TOBEFILLED-EduApp,
  author    = {van der Wees, Marlies  and  Bisazza, Arianna  and  Monz, Christof},
  title     = {Dynamic Data Selection for Neural Machine Translation},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {1409--1419},
  abstract  = {Intelligent selection of training data has proven a successful technique to
	simultaneously increase training efficiency and translation performance for
	phrase-based machine translation (PBMT). With the recent increase in popularity
	of neural machine translation (NMT), we explore in this paper to what extent
	and how NMT can also benefit from data selection. While state-of-the-art data
	selection (Axelrod et al., 2011) consistently performs well for PBMT, we show
	that gains are substantially lower for NMT. Next, we introduce 'dynamic data
	selection' for NMT, a method in which we vary the selected subset of training
	data between different training epochs. Our experiments show that the best
	results are achieved when applying a technique we call 'gradual fine-tuning',
	with improvements up to +2.6 BLEU over the original data selection approach and
	up to +3.1 BLEU over a general baseline.},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1148, http://www.aclweb.org/anthology/W17-20 0}
}

