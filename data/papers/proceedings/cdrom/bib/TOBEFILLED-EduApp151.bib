@InProceedings{yang-EtAl:0:TOBEFILLED-EduApp2,
  author    = {Yang, Baosong  and  Wong, Derek F.  and  Xiao, Tong  and  Chao, Lidia S.  and  Zhu, Jingbo},
  title     = {Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {1441--1450},
  abstract  = {This paper proposes a hierarchical attentional neural translation model which
	focuses on enhancing source-side hierarchical representations by covering both
	local and global semantic information using a bidirectional tree-based encoder.
	To maximize the predictive likelihood of target words, a weighted variant of an
	attention mechanism is used to balance the attentive information between
	lexical and phrase vectors. Using a tree-based rare word encoding, the proposed
	model is extended to sub-word level to alleviate the out-of-vocabulary (OOV)
	problem. Empirical results reveal that the proposed model significantly
	outperforms sequence-to-sequence attention-based and tree-based neural
	translation models in English-Chinese translation tasks.},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1151, http://www.aclweb.org/anthology/W17-20 0}
}

