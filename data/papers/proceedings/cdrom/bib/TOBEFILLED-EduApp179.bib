@InProceedings{zhang-EtAl:0:TOBEFILLED-EduApp4,
  author    = {Zhang, Xiao  and  Jiang, Yong  and  Peng, Hao  and  Tu, Kewei  and  Goldwasser, Dan},
  title     = {Semi-supervised Structured Prediction with Neural CRF Autoencoder},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {1700--1710},
  abstract  = {In this paper we propose an end-to-end neural CRF autoencoder (NCRF-AE) model
	for semi-supervised learning of sequential structured prediction problems. Our
	NCRF-AE consists of two parts: an encoder which is a CRF model enhanced by deep
	neural networks, and a decoder which is a generative model trying to
	reconstruct the input. Our model has a unified structure with different loss
	functions for labeled and unlabeled data with shared parameters. We developed a
	variation of the EM algorithm for optimizing both the encoder and the decoder
	simultaneously by decoupling their parameters. Our Experimental results over
	the Part-of-Speech (POS) tagging task on eight different languages, show that
	our model can outperform competitive systems in both supervised and
	semi-supervised scenarios.},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1179, http://www.aclweb.org/anthology/W17-20 0}
}

