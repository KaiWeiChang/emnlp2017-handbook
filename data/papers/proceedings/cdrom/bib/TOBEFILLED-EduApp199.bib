@InProceedings{assylbekov-EtAl:0:TOBEFILLED-EduApp,
  author    = {Assylbekov, Zhenisbek  and  Takhanov, Rustem  and  Myrzakhmetov, Bagdat  and  Washington, Jonathan N.},
  title     = {Syllable-aware Neural Language Models: A Failure to Beat Character-aware Ones},
  booktitle = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month     = {TOBEFILLED-June},
  year      = {TOBEFILLED-1},
  address   = {TOBEFILLED-Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {1866--1872},
  abstract  = {Syllabification does not seem to improve word-level RNN language modeling
	quality when compared to character-based segmentation. However, our best
	syllable-aware language model, achieving performance comparable to the
	competitive character-aware model, has 18%-33% fewer parameters and is trained
	1.2-2.2 times faster.},
  url       = {TOBEFILLED-e.g, http://www.aclweb.org/anthology/P17-1199, http://www.aclweb.org/anthology/W17-20 0}
}

