SubmissionNumber#=%=#1310
FinalPaperTitle#=%=#Maximum Margin Reward Networks for Learning from Explicit and Implicit Supervision
ShortPaperTitle#=%=#Maximum Margin Reward Networks for Learning from Explicit and Implicit Supervision
NumberOfPages#=%=#11
CopyrightSigned#=%=#Haoruo Peng
JobTitle#==#
Organization#==#University of Illinois, Urbana-Champaign
Urbana, IL, 61801
Abstract#==#Neural networks have achieved state-of-the-art performance on several
structured-output prediction tasks, trained in a fully supervised
fashion.  However, annotated examples in structured domains are often
costly to obtain, which thus limits the applications of neural
networks.  In this work, we propose Maximum Margin Reward Networks, a
neural network-based framework that aims to learn from both explicit
(full structures) and implicit supervision signals (delayed feedback
on the correctness of the predicted structure).  On named entity
recognition and semantic parsing, our model outperforms previous
systems on the benchmark datasets, CoNLL-2003 and WebQuestionsSP.
Author{1}{Firstname}#=%=#Haoruo
Author{1}{Lastname}#=%=#Peng
Author{1}{Email}#=%=#hpeng7@illinois.edu
Author{1}{Affiliation}#=%=#UIUC
Author{2}{Firstname}#=%=#Ming-Wei
Author{2}{Lastname}#=%=#Chang
Author{2}{Email}#=%=#changmingwei@gmail.com
Author{2}{Affiliation}#=%=#Microsoft Research
Author{3}{Firstname}#=%=#Wen-tau
Author{3}{Lastname}#=%=#Yih
Author{3}{Email}#=%=#scottyih@microsoft.com
Author{3}{Affiliation}#=%=#Microsoft Research

==========