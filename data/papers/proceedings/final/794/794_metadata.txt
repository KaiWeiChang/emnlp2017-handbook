SubmissionNumber#=%=#794
FinalPaperTitle#=%=#Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning
ShortPaperTitle#=%=#Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning
NumberOfPages#=%=#6
CopyrightSigned#=%=#Felix Hieber
JobTitle#==#Author
Organization#==#Amazon Development Center Germany GmbH
Krausenstrasse 38
10117 Berlin
Abstract#==#The performance of Neural Machine Translation (NMT) models relies heavily on
the availability of sufficient amounts of parallel data, and an efficient and
effective way of leveraging the vastly available amounts of monolingual data
has yet to be found.
We propose to modify the decoder in a neural sequence-to-sequence model to
enable multi-task learning for two strongly related tasks: target-side language
modeling and translation.
The decoder predicts the next target word through two channels, a target-side
language model on the lowest layer, and an attentional recurrent model which is
conditioned on the source representation.
This architecture allows joint training on both large amounts of monolingual
and moderate amounts of bilingual data to improve NMT performance.
Initial results in the news domain for three language pairs show moderate but
consistent improvements over a baseline trained on bilingual data only.
Author{1}{Firstname}#=%=#Tobias
Author{1}{Lastname}#=%=#Domhan
Author{1}{Email}#=%=#domhant@amazon.com
Author{1}{Affiliation}#=%=#Amazon Research
Author{2}{Firstname}#=%=#Felix
Author{2}{Lastname}#=%=#Hieber
Author{2}{Email}#=%=#fhieber@amazon.de
Author{2}{Affiliation}#=%=#Amazon Research

==========