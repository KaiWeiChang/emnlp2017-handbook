SubmissionNumber#=%=#663
FinalPaperTitle#=%=#Dict2vec : Learning Word Embeddings using Lexical Dictionaries
ShortPaperTitle#=%=#Dict2vec : Learning Word Embeddings using Lexical Dictionaries
NumberOfPages#=%=#10
CopyrightSigned#=%=#Julien Tissier
JobTitle#==#
Organization#==#
Abstract#==#Learning word embeddings on large unlabeled corpus has been shown to be
successful in improving many natural language tasks. The most efficient and
popular approaches learn or retrofit such representations using additional
external data. Resulting embeddings are generally better than their corpus-only
counterparts, although such resources cover a fraction of words in the
vocabulary. In this paper, we propose a new approach, Dict2vec, based on one of
the largest yet refined datasource for describing words – natural language
dictionaries. Dict2vec builds new word pairs from dictionary entries so that
semantically-related words are moved closer, and negative sampling filters out
pairs whose words are unrelated in dictionaries. We evaluate the word
representations obtained using Dict2vec on eleven datasets for the word
similarity task and on four datasets for a text classification task.
Author{1}{Firstname}#=%=#Julien
Author{1}{Lastname}#=%=#Tissier
Author{1}{Email}#=%=#julien.tissier@univ-st-etienne.fr
Author{1}{Affiliation}#=%=#Laboratoire Hubert Curien UMR CNRS 5516, Saint-Etienne
Author{2}{Firstname}#=%=#Christopher
Author{2}{Lastname}#=%=#Gravier
Author{2}{Email}#=%=#christophe.gravier@univ-st-etienne.fr
Author{2}{Affiliation}#=%=#Université Jean Monnet
Author{3}{Firstname}#=%=#Amaury
Author{3}{Lastname}#=%=#Habrard
Author{3}{Email}#=%=#amaury.habrard@univ-st-etienne.fr
Author{3}{Affiliation}#=%=#University of Saint-Etienne

==========