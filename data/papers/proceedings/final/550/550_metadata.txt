SubmissionNumber#=%=#550
FinalPaperTitle#=%=#Deep Recurrent Generative Decoder for Abstractive Text Summarization
ShortPaperTitle#=%=#Deep Recurrent Generative Decoder for Abstractive Text Summarization
NumberOfPages#=%=#10
CopyrightSigned#=%=#Piji Li
JobTitle#==#
Organization#==#Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong, Shatin, Hong Kong, China
Abstract#==#We propose a new framework for abstractive text summarization based on a
sequence-to-sequence oriented encoder-decoder model equipped with a deep
recurrent generative decoder (DRGN).
  Latent structure information implied in the target summaries is learned based
on a recurrent latent random model for improving the summarization quality.
  Neural variational inference is employed to address the intractable posterior
inference for the recurrent latent variables.
  Abstractive summaries are generated based on both the generative latent
variables and the discriminative deterministic states.
  Extensive experiments on some benchmark datasets in different languages show
that DRGN achieves improvements over the state-of-the-art methods.
Author{1}{Firstname}#=%=#Piji
Author{1}{Lastname}#=%=#Li
Author{1}{Email}#=%=#lipiji.pz@gmail.com
Author{1}{Affiliation}#=%=#The Chinese University of Hong Kong
Author{2}{Firstname}#=%=#Wai
Author{2}{Lastname}#=%=#Lam
Author{2}{Email}#=%=#wlam@se.cuhk.edu.hk
Author{2}{Affiliation}#=%=#The Chinese University of Hong Kong
Author{3}{Firstname}#=%=#Lidong
Author{3}{Lastname}#=%=#Bing
Author{3}{Email}#=%=#binglidong@gmail.com
Author{3}{Affiliation}#=%=#AI Lab, Tencent Inc.
Author{4}{Firstname}#=%=#Zihao
Author{4}{Lastname}#=%=#Wang
Author{4}{Email}#=%=#zhwang@se.cuhk.edu.hk
Author{4}{Affiliation}#=%=#The Chinese University of Hong Kong

==========