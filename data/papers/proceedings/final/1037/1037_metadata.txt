SubmissionNumber#=%=#1037
FinalPaperTitle#=%=#Sound-Word2Vec: Learning Word Representations Grounded in Sounds
ShortPaperTitle#=%=#Sound-Word2Vec: Learning Word Representations Grounded in Sounds
NumberOfPages#=%=#6
CopyrightSigned#=%=#Ashwin K Vijayakumar
JobTitle#==#
Organization#==#Georgia Tech
North Ave NW, Atlanta, GA 30332, USA
Abstract#==#To be able to interact better with humans, it is crucial for machines to
understand sound – a primary modality of human perception. Previous works
have used sound to learn embeddings for improved generic semantic similarity
assessment. In this work, we treat sound as a first-class citizen, studying
downstream 6textual tasks which require aural grounding. To this end, we
propose sound-word2vec – a new embedding scheme that learns specialized word
embeddings grounded in sounds. For example, we learn that two seemingly (se-
mantically) unrelated concepts, like leaves and paper are similar due to the
similar rustling sounds they make. Our embed- dings prove useful in textual
tasks requiring aural reasoning like text-based sound retrieval and discovering
Foley sound effects (used in movies). Moreover, our em- bedding space captures
interesting dependencies between words and onomatopoeia and outperforms prior
work on aurally- relevant word relatedness datasets such as AMEN and ASLex.
Author{1}{Firstname}#=%=#Ashwin
Author{1}{Lastname}#=%=#Vijayakumar
Author{1}{Email}#=%=#ashwinkv@gatech.edu
Author{1}{Affiliation}#=%=#Georgia Institute of Technology
Author{2}{Firstname}#=%=#Ramakrishna
Author{2}{Lastname}#=%=#Vedantam
Author{2}{Email}#=%=#vrama91@vt.edu
Author{2}{Affiliation}#=%=#Virginia Tech
Author{3}{Firstname}#=%=#Devi
Author{3}{Lastname}#=%=#Parikh
Author{3}{Email}#=%=#parikh@gt.edu
Author{3}{Affiliation}#=%=#Georgia Institute of Technology

==========