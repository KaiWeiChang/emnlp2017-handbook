SubmissionNumber#=%=#308
FinalPaperTitle#=%=#End-to-End Neural Relation Extraction with Global Optimization
ShortPaperTitle#=%=#End-to-End Neural Relation Extraction with Global Optimization
NumberOfPages#=%=#11
CopyrightSigned#=%=#meishan zhang
JobTitle#==#
Organization#==#
Abstract#==#Neural networks have shown promising results for relation extraction.
State-of-the-art models cast the task as an end-to-end problem, 
solved incrementally using a local classifier.
Yet previous work using statistical models have demonstrated that global
optimization can achieve better performances compared to local classification.
We build a globally optimized neural model for end-to-end relation extraction,
proposing novel LSTM features in order to better learn context representations.
In addition, we present a novel method to integrate syntactic information to
facilitate global learning, yet requiring little background on syntactic
grammars thus being easy to extend. Experimental results show that our proposed
model is highly effective,
achieving the best performances on two standard benchmarks.
Author{1}{Firstname}#=%=#Meishan
Author{1}{Lastname}#=%=#Zhang
Author{1}{Email}#=%=#mszhang@ir.hit.edu.cn
Author{1}{Affiliation}#=%=#Heilongjiang University
Author{2}{Firstname}#=%=#Yue
Author{2}{Lastname}#=%=#Zhang
Author{2}{Email}#=%=#yue_zhang@sutd.edu.sg
Author{2}{Affiliation}#=%=#Singapore University of Technology and Design
Author{3}{Firstname}#=%=#Guohong
Author{3}{Lastname}#=%=#Fu
Author{3}{Email}#=%=#ghfu@hotmail.com
Author{3}{Affiliation}#=%=#Heilongjiang University

==========