SubmissionNumber#=%=#992
FinalPaperTitle#=%=#Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation
ShortPaperTitle#=%=#Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation
NumberOfPages#=%=#10
CopyrightSigned#=%=#Baosong Yang
JobTitle#==#
Organization#==#NLP2CT Lab, E11-2023, Faculty of Science and Technology, University of Macau, Avenida da Universidade, Taipa, Macau, China
Abstract#==#This paper proposes a hierarchical attentional neural translation model which
focuses on enhancing source-side hierarchical representations by covering both
local and global semantic information using a bidirectional tree-based encoder.
To maximize the predictive likelihood of target words, a weighted variant of an
attention mechanism is used to balance the attentive information between
lexical and phrase vectors. Using a tree-based rare word encoding, the proposed
model is extended to sub-word level to alleviate the out-of-vocabulary (OOV)
problem. Empirical results reveal that the proposed model significantly
outperforms sequence-to-sequence attention-based and tree-based neural
translation models in English-Chinese translation tasks.
Author{1}{Firstname}#=%=#Baosong
Author{1}{Lastname}#=%=#Yang
Author{1}{Email}#=%=#nlp2ct.baosong@gmail.com
Author{1}{Affiliation}#=%=#NLP2CT Lab, Department of Computer and Information Science, University of Macau
Author{2}{Firstname}#=%=#Derek F.
Author{2}{Lastname}#=%=#Wong
Author{2}{Email}#=%=#derekfw@umac.mo
Author{2}{Affiliation}#=%=#University of Macau
Author{3}{Firstname}#=%=#Tong
Author{3}{Lastname}#=%=#Xiao
Author{3}{Email}#=%=#xiaotong@mail.neu.edu.cn
Author{3}{Affiliation}#=%=#NiuTrans Lab, Northeastern University, China
Author{4}{Firstname}#=%=#Lidia S.
Author{4}{Lastname}#=%=#Chao
Author{4}{Email}#=%=#lidiasc@umac.mo
Author{4}{Affiliation}#=%=#University of Macau
Author{5}{Firstname}#=%=#Jingbo
Author{5}{Lastname}#=%=#Zhu
Author{5}{Email}#=%=#zhujingbo@mail.neu.edu.cn
Author{5}{Affiliation}#=%=#Northeastern University

==========