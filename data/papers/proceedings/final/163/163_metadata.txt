SubmissionNumber#=%=#163
FinalPaperTitle#=%=#Incorporating Global Visual Features into Attention-based Neural Machine Translation.
ShortPaperTitle#=%=#Incorporating Global Visual Features into Attention-based Neural Machine Translation.
NumberOfPages#=%=#12
CopyrightSigned#=%=#Iacer Calixto
JobTitle#==#
Organization#==#ADAPT Centre, Dublin City University, Glasnevin, Dublin 9.
Abstract#==#We introduce multi-modal, attention-based neural machine translation (NMT)
models which incorporate visual features into different parts of both the
encoder and the decoder. Global image features are extracted using a
pre-trained convolutional neural network and are incorporated (i) as words in
the source sentence, (ii) to initialise the encoder hidden state, and (iii) as
additional data to initialise the decoder hidden state. In our experiments, we
evaluate translations into English and German, how different strategies to
incorporate global image features compare and which ones perform best. We also
study the impact that adding synthetic multi-modal, multilingual data brings
and find that the additional data have a positive impact on multi-modal NMT
models. We report new state-of-the-art results and our best models also
significantly improve on a comparable phrase-based Statistical MT (PBSMT) model
trained on the Multi30k data set according to all metrics evaluated. To the
best of our knowledge, it is the first time a purely neural model significantly
improves over a PBSMT model on all metrics evaluated on this data set.
Author{1}{Firstname}#=%=#Iacer
Author{1}{Lastname}#=%=#Calixto
Author{1}{Email}#=%=#calixto.iacer@gmail.com
Author{1}{Affiliation}#=%=#Dublin City University
Author{2}{Firstname}#=%=#Qun
Author{2}{Lastname}#=%=#Liu
Author{2}{Email}#=%=#qun.liu@dcu.ie
Author{2}{Affiliation}#=%=#Dublin City University

==========