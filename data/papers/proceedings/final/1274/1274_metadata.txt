SubmissionNumber#=%=#1274
FinalPaperTitle#=%=#Knowledge Distillation for Bilingual Dictionary Induction
ShortPaperTitle#=%=#Knowledge Distillation for Bilingual Dictionary Induction
NumberOfPages#=%=#10
CopyrightSigned#=%=#NN
JobTitle#==#Assistant Professor
Organization#==#UCSD
La Jolla, CA
Abstract#==#Leveraging zero-shot learning to learn
mapping functions between vector spaces
of different languages is a promising approach
to bilingual dictionary induction.
However, methods using this approach
have not yet achieved high accuracy on the
task. In this paper, we propose a bridging
approach, where our main contribution
is a knowledge distillation training objective.
As teachers, rich resource translation
paths are exploited in this role. And
as learners, translation paths involving low
resource languages learn from the teachers.
Our training objective allows seamless
addition of teacher translation paths
for any given low resource pair. Since our
approach relies on the quality of monolingual
word embeddings, we also propose to
enhance vector representations of both the
source and target language with linguistic
information. Our experiments on various
languages show large performance gains
from our distillation training objective, obtaining
as high as 17% accuracy improvements.
Author{1}{Firstname}#=%=#Ndapandula
Author{1}{Lastname}#=%=#Nakashole
Author{1}{Email}#=%=#nnakashole@eng.ucsd.edu
Author{1}{Affiliation}#=%=#University of California, San Diego
Author{2}{Firstname}#=%=#Raphael
Author{2}{Lastname}#=%=#Flauger
Author{2}{Email}#=%=#flauger@ucsd.edu
Author{2}{Affiliation}#=%=#University of California, San Diego

==========