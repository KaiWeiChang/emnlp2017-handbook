\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Monolingual Phrase Alignment on Parse Forests}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_617}{{1}{1}{Monolingual Phrase Alignment on Parse Forests\relax }{chapter.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fast(er) Exact Decoding and Global Training for Transition-Based Dependency Parsing via a Minimal Feature Set}{12}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1381}{{2}{12}{Fast(er) Exact Decoding and Global Training for Transition-Based Dependency Parsing via a Minimal Feature Set\relax }{chapter.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Quasi-Second-Order Parsing for 1-Endpoint-Crossing, Pagenumber-2 Graphs}{24}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1501}{{3}{24}{Quasi-Second-Order Parsing for 1-Endpoint-Crossing, Pagenumber-2 Graphs\relax }{chapter.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Position-aware Attention and Supervised Data Improve Slot Filling}{35}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1417}{{4}{35}{Position-aware Attention and Supervised Data Improve Slot Filling\relax }{chapter.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach}{46}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1321}{{5}{46}{Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach\relax }{chapter.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Integrating Order Information and Event Relation for Script Event Prediction}{57}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1082}{{6}{57}{Integrating Order Information and Event Relation for Script Event Prediction\relax }{chapter.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Entity Linking for Queries by Searching Wikipedia Sentences}{68}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_313}{{7}{68}{Entity Linking for Queries by Searching Wikipedia Sentences\relax }{chapter.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Train-O-Matic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data}{78}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_336}{{8}{78}{Train-O-Matic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data\relax }{chapter.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Universal Semantic Parsing}{89}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_857}{{9}{89}{Universal Semantic Parsing\relax }{chapter.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Mimicking Word Embeddings using Subword RNNs}{102}{chapter.10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1195}{{10}{102}{Mimicking Word Embeddings using Subword RNNs\relax }{chapter.10}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Past, Present, Future: A Computational Investigation of the Typology of Tense in 1000 Languages}{113}{chapter.11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_963}{{11}{113}{Past, Present, Future: A Computational Investigation of the Typology of Tense in 1000 Languages\relax }{chapter.11}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Neural Machine Translation with Source-Side Latent Graph Parsing}{125}{chapter.12}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_994}{{12}{125}{Neural Machine Translation with Source-Side Latent Graph Parsing\relax }{chapter.12}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Neural Machine Translation with Word Predictions}{136}{chapter.13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1213}{{13}{136}{Neural Machine Translation with Word Predictions\relax }{chapter.13}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Towards Decoding as Continuous Optimisation in Neural Machine Translation}{146}{chapter.14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1250}{{14}{146}{Towards Decoding as Continuous Optimisation in Neural Machine Translation\relax }{chapter.14}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Where is Misty? Interpreting Spatial Descriptors by Modeling Regions in Space}{157}{chapter.15}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1085}{{15}{157}{Where is Misty? Interpreting Spatial Descriptors by Modeling Regions in Space\relax }{chapter.15}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {16}Continuous Representation of Location for Geolocation and Lexical Dialectology using Mixture Density Networks}{167}{chapter.16}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_480}{{16}{167}{Continuous Representation of Location for Geolocation and Lexical Dialectology using Mixture Density Networks\relax }{chapter.16}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {17}Obj2Text: Generating Visually Descriptive Language from Object Layouts}{177}{chapter.17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1367}{{17}{177}{Obj2Text: Generating Visually Descriptive Language from Object Layouts\relax }{chapter.17}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {18}End-to-end Neural Coreference Resolution}{188}{chapter.18}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_912}{{18}{188}{End-to-end Neural Coreference Resolution\relax }{chapter.18}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {19}Neural Net Models of Open-domain Discourse Coherence}{198}{chapter.19}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_20}{{19}{198}{Neural Net Models of Open-domain Discourse Coherence\relax }{chapter.19}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {20}Affinity-Preserving Random Walk for Multi-Document Summarization}{210}{chapter.20}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_524}{{20}{210}{Affinity-Preserving Random Walk for Multi-Document Summarization\relax }{chapter.20}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {21}A Mention-Ranking Model for Abstract Anaphora Resolution}{221}{chapter.21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_779}{{21}{221}{A Mention-Ranking Model for Abstract Anaphora Resolution\relax }{chapter.21}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {22}Hierarchical Embeddings for Hypernymy Detection and Directionality}{233}{chapter.22}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_188}{{22}{233}{Hierarchical Embeddings for Hypernymy Detection and Directionality\relax }{chapter.22}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {23}Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics}{244}{chapter.23}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_193}{{23}{244}{Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics\relax }{chapter.23}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {24}Dict2vec : Learning Word Embeddings using Lexical Dictionaries}{254}{chapter.24}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_663}{{24}{254}{Dict2vec : Learning Word Embeddings using Lexical Dictionaries\relax }{chapter.24}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {25}Learning Chinese Word Representations From Glyphs Of Characters}{264}{chapter.25}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1197}{{25}{264}{Learning Chinese Word Representations From Glyphs Of Characters\relax }{chapter.25}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {26}Learning Paraphrastic Sentence Embeddings from Back-Translated Bitext}{274}{chapter.26}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1396}{{26}{274}{Learning Paraphrastic Sentence Embeddings from Back-Translated Bitext\relax }{chapter.26}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {27}Joint Embeddings of Chinese Words, Characters, and Fine-grained Subcharacter Components}{286}{chapter.27}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_102}{{27}{286}{Joint Embeddings of Chinese Words, Characters, and Fine-grained Subcharacter Components\relax }{chapter.27}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {28}Exploiting Morphological Regularities in Distributional Word Representations}{292}{chapter.28}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_427}{{28}{292}{Exploiting Morphological Regularities in Distributional Word Representations\relax }{chapter.28}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {29}Exploiting Word Internal Structures for Generic Chinese Sentence Representation}{298}{chapter.29}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_600}{{29}{298}{Exploiting Word Internal Structures for Generic Chinese Sentence Representation\relax }{chapter.29}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {30}High-risk learning: acquiring new word vectors from tiny data}{304}{chapter.30}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_853}{{30}{304}{High-risk learning: acquiring new word vectors from tiny data\relax }{chapter.30}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {31}Word Embeddings based on Fixed-Size Ordinally Forgetting Encoding}{310}{chapter.31}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_884}{{31}{310}{Word Embeddings based on Fixed-Size Ordinally Forgetting Encoding\relax }{chapter.31}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {32}VecShare: A Framework for Sharing Word Representation Vectors}{316}{chapter.32}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_990}{{32}{316}{VecShare: A Framework for Sharing Word Representation Vectors\relax }{chapter.32}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {33}Word Re-Embedding via Manifold Dimensionality Retention}{321}{chapter.33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_898}{{33}{321}{Word Re-Embedding via Manifold Dimensionality Retention\relax }{chapter.33}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {34}MUSE: Modularizing Unsupervised Sense Embeddings}{327}{chapter.34}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1302}{{34}{327}{MUSE: Modularizing Unsupervised Sense Embeddings\relax }{chapter.34}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {35}Reporting Score Distributions Makes a Difference: Performance Study of LSTM-networks for Sequence Tagging}{338}{chapter.35}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_65}{{35}{338}{Reporting Score Distributions Makes a Difference: Performance Study of LSTM-networks for Sequence Tagging\relax }{chapter.35}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {36}Learning What's Easy: Fully Differentiable Neural Easy-First Taggers}{349}{chapter.36}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_111}{{36}{349}{Learning What's Easy: Fully Differentiable Neural Easy-First Taggers\relax }{chapter.36}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {37}Incremental Skip-gram Model with Negative Sampling}{361}{chapter.37}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_516}{{37}{361}{Incremental Skip-gram Model with Negative Sampling\relax }{chapter.37}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {38}Learning to select data for transfer learning with Bayesian Optimization}{370}{chapter.38}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_737}{{38}{370}{Learning to select data for transfer learning with Bayesian Optimization\relax }{chapter.38}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {39}Unsupervised Pretraining for Sequence to Sequence Learning}{381}{chapter.39}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_754}{{39}{381}{Unsupervised Pretraining for Sequence to Sequence Learning\relax }{chapter.39}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {40}Efficient Attention using a Fixed-Size Memory Representation}{390}{chapter.40}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1046}{{40}{390}{Efficient Attention using a Fixed-Size Memory Representation\relax }{chapter.40}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {41}Rotated Word Vector Representations and their Interpretability}{399}{chapter.41}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1211}{{41}{399}{Rotated Word Vector Representations and their Interpretability\relax }{chapter.41}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {42}A causal framework for explaining the predictions of black-box sequence-to-sequence models}{410}{chapter.42}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1260}{{42}{410}{A causal framework for explaining the predictions of black-box sequence-to-sequence models\relax }{chapter.42}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {43}Piecewise Latent Variables for Neural Variational Text Processing}{420}{chapter.43}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1462}{{43}{420}{Piecewise Latent Variables for Neural Variational Text Processing\relax }{chapter.43}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {44}Learning the Structure of Variable-Order CRFs: a finite-state perspective}{431}{chapter.44}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_690}{{44}{431}{Learning the Structure of Variable-Order CRFs: a finite-state perspective\relax }{chapter.44}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {45}Sparse Communication for Distributed Gradient Descent}{438}{chapter.45}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_864}{{45}{438}{Sparse Communication for Distributed Gradient Descent\relax }{chapter.45}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {46}A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks}{444}{chapter.46}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1011}{{46}{444}{A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks\relax }{chapter.46}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {47}Why ADAGRAD Fails for Online Topic Modeling}{455}{chapter.47}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1229}{{47}{455}{Why ADAGRAD Fails for Online Topic Modeling\relax }{chapter.47}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {48}Recurrent Attention Network on Memory for Aspect Sentiment Analysis}{461}{chapter.48}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_215}{{48}{461}{Recurrent Attention Network on Memory for Aspect Sentiment Analysis\relax }{chapter.48}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {49}A Cognition Based Attention Model for Sentiment Analysis}{471}{chapter.49}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_378}{{49}{471}{A Cognition Based Attention Model for Sentiment Analysis\relax }{chapter.49}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {50}Author-aware Aspect Topic Sentiment Model to Retrieve Supporting Opinions from Reviews}{481}{chapter.50}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_623}{{50}{481}{Author-aware Aspect Topic Sentiment Model to Retrieve Supporting Opinions from Reviews\relax }{chapter.50}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {51}Magnets for Sarcasm: Making Sarcasm Detection Timely, Contextual and Very Personal}{491}{chapter.51}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_988}{{51}{491}{Magnets for Sarcasm: Making Sarcasm Detection Timely, Contextual and Very Personal\relax }{chapter.51}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {52}Identifying Humor in Reviews using Background Text Sources}{501}{chapter.52}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1118}{{52}{501}{Identifying Humor in Reviews using Background Text Sources\relax }{chapter.52}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {53}Sentiment Lexicon Construction with Representation Learning Based on Hierarchical Sentiment Supervision}{511}{chapter.53}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1169}{{53}{511}{Sentiment Lexicon Construction with Representation Learning Based on Hierarchical Sentiment Supervision\relax }{chapter.53}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {54}Towards a Universal Sentiment Classifier in Multiple languages}{520}{chapter.54}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1399}{{54}{520}{Towards a Universal Sentiment Classifier in Multiple languages\relax }{chapter.54}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {55}Capturing User and Product Information for Document Level Sentiment Analysis with Deep Memory Network}{530}{chapter.55}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_696}{{55}{530}{Capturing User and Product Information for Document Level Sentiment Analysis with Deep Memory Network\relax }{chapter.55}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {56}Identifying and Tracking Sentiments and Topics from Social Media Texts during Natural Disasters}{536}{chapter.56}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_948}{{56}{536}{Identifying and Tracking Sentiments and Topics from Social Media Texts during Natural Disasters\relax }{chapter.56}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {57}Refining Word Embeddings for Sentiment Analysis}{543}{chapter.57}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1126}{{57}{543}{Refining Word Embeddings for Sentiment Analysis\relax }{chapter.57}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {58}A Multilayer Perceptron based Ensemble Technique for Fine-grained Financial Sentiment Analysis}{549}{chapter.58}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1416}{{58}{549}{A Multilayer Perceptron based Ensemble Technique for Fine-grained Financial Sentiment Analysis\relax }{chapter.58}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {59}Sentiment Intensity Ranking among Adjectives Using Sentiment Bearing Word Embeddings}{556}{chapter.59}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1436}{{59}{556}{Sentiment Intensity Ranking among Adjectives Using Sentiment Bearing Word Embeddings\relax }{chapter.59}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {60}Sentiment Lexicon Expansion Based on Neural PU Learning, Double Dictionary Lookup, and Polarity Association}{562}{chapter.60}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_723}{{60}{562}{Sentiment Lexicon Expansion Based on Neural PU Learning, Double Dictionary Lookup, and Polarity Association\relax }{chapter.60}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {61}DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning}{573}{chapter.61}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1047}{{61}{573}{DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning\relax }{chapter.61}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {62}Task-Oriented Query Reformulation with Reinforcement Learning}{583}{chapter.62}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_434}{{62}{583}{Task-Oriented Query Reformulation with Reinforcement Learning\relax }{chapter.62}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {63}Sentence Simplification with Deep Reinforcement Learning}{593}{chapter.63}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_437}{{63}{593}{Sentence Simplification with Deep Reinforcement Learning\relax }{chapter.63}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {64}Learning how to Active Learn: A Deep Reinforcement Learning Approach}{604}{chapter.64}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_679}{{64}{604}{Learning how to Active Learn: A Deep Reinforcement Learning Approach\relax }{chapter.64}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {65}Split and Rephrase}{615}{chapter.65}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_842}{{65}{615}{Split and Rephrase\relax }{chapter.65}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {66}Neural Response Generation via GAN with an Approximate Embedding Layer}{626}{chapter.66}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1344}{{66}{626}{Neural Response Generation via GAN with an Approximate Embedding Layer\relax }{chapter.66}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {67}A Hybrid Convolutional Variational Autoencoder for Text Generation}{636}{chapter.67}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_591}{{67}{636}{A Hybrid Convolutional Variational Autoencoder for Text Generation\relax }{chapter.67}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {68}Filling the Blanks (hint: plural noun) for Mad Libs Humor}{647}{chapter.68}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1035}{{68}{647}{Filling the Blanks (hint: plural noun) for Mad Libs Humor\relax }{chapter.68}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {69}Measuring Thematic Fit with Distributional Feature Overlap}{657}{chapter.69}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_84}{{69}{657}{Measuring Thematic Fit with Distributional Feature Overlap\relax }{chapter.69}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {70}SCDV : Sparse Composite Document Vectors using soft clustering over distributional representations}{668}{chapter.70}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_822}{{70}{668}{SCDV : Sparse Composite Document Vectors using soft clustering over distributional representations\relax }{chapter.70}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {71}Supervised Learning of Universal Sentence Representations from Natural Language Inference Data}{679}{chapter.71}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_871}{{71}{679}{Supervised Learning of Universal Sentence Representations from Natural Language Inference Data\relax }{chapter.71}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {72}Determining Semantic Textual Similarity using Natural Deduction Proofs}{690}{chapter.72}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_624}{{72}{690}{Determining Semantic Textual Similarity using Natural Deduction Proofs\relax }{chapter.72}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {73}Multi-Grained Chinese Word Segmentation}{701}{chapter.73}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_43}{{73}{701}{Multi-Grained Chinese Word Segmentation\relax }{chapter.73}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {74}Don't Throw Those Morphological Analyzers Away Just Yet: Neural Morphological Disambiguation for Arabic}{713}{chapter.74}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_996}{{74}{713}{Don't Throw Those Morphological Analyzers Away Just Yet: Neural Morphological Disambiguation for Arabic\relax }{chapter.74}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {75}Paradigm Completion for Derivational Morphology}{723}{chapter.75}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_127}{{75}{723}{Paradigm Completion for Derivational Morphology\relax }{chapter.75}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {76}A Sub-Character Architecture for Korean Language Processing}{730}{chapter.76}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_650}{{76}{730}{A Sub-Character Architecture for Korean Language Processing\relax }{chapter.76}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {77}Do LSTMs really work so well for PoS tagging? -- A replication study}{736}{chapter.77}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_39}{{77}{736}{Do LSTMs really work so well for PoS tagging? -- A replication study\relax }{chapter.77}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {78}The Labeled Segmentation of Printed Books}{746}{chapter.78}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_446}{{78}{746}{The Labeled Segmentation of Printed Books\relax }{chapter.78}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {79}Cross-lingual Character-Level Neural Morphological Tagging}{757}{chapter.79}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_128}{{79}{757}{Cross-lingual Character-Level Neural Morphological Tagging\relax }{chapter.79}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {80}Word-Context Character Embeddings for Chinese Word Segmentation}{769}{chapter.80}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1299}{{80}{769}{Word-Context Character Embeddings for Chinese Word Segmentation\relax }{chapter.80}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {81}Segmentation-Free Word Embedding for Unsegmented Languages}{776}{chapter.81}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_44}{{81}{776}{Segmentation-Free Word Embedding for Unsegmented Languages\relax }{chapter.81}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {82}From Textbooks to Knowledge: A Case Study in Harvesting Axiomatic Knowledge from Textbooks to Solve Geometry Problems}{782}{chapter.82}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_22}{{82}{782}{From Textbooks to Knowledge: A Case Study in Harvesting Axiomatic Knowledge from Textbooks to Solve Geometry Problems\relax }{chapter.82}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {83}RACE: Large-scale ReAding Comprehension Dataset From Examinations}{794}{chapter.83}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_37}{{83}{794}{RACE: Large-scale ReAding Comprehension Dataset From Examinations\relax }{chapter.83}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {84}Beyond Sentential Semantic Parsing: Tackling the Math SAT with a Cascade of Tree Transducers}{804}{chapter.84}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_432}{{84}{804}{Beyond Sentential Semantic Parsing: Tackling the Math SAT with a Cascade of Tree Transducers\relax }{chapter.84}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {85}Learning Fine-Grained Expressions to Solve Math Word Problems}{814}{chapter.85}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_627}{{85}{814}{Learning Fine-Grained Expressions to Solve Math Word Problems\relax }{chapter.85}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {86}Structural Embedding of Syntactic Trees for Machine Comprehension}{824}{chapter.86}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1219}{{86}{824}{Structural Embedding of Syntactic Trees for Machine Comprehension\relax }{chapter.86}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {87}World Knowledge for Reading Comprehension: Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions}{834}{chapter.87}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_856}{{87}{834}{World Knowledge for Reading Comprehension: Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions\relax }{chapter.87}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {88}Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension}{844}{chapter.88}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1145}{{88}{844}{Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension\relax }{chapter.88}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {89}Deep Neural Solver for Math Word Problems}{854}{chapter.89}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_359}{{89}{854}{Deep Neural Solver for Math Word Problems\relax }{chapter.89}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {90}Latent Space Embedding for Retrieval in Question-Answer Archives}{864}{chapter.90}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_72}{{90}{864}{Latent Space Embedding for Retrieval in Question-Answer Archives\relax }{chapter.90}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {91}Question Generation for Question Answering}{875}{chapter.91}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_294}{{91}{875}{Question Generation for Question Answering\relax }{chapter.91}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {92}Learning to Paraphrase for Question Answering}{884}{chapter.92}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_770}{{92}{884}{Learning to Paraphrase for Question Answering\relax }{chapter.92}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {93}Temporal Information Extraction for Question Answering Using Syntactic Dependencies in an LSTM-based Architecture}{896}{chapter.93}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1419}{{93}{896}{Temporal Information Extraction for Question Answering Using Syntactic Dependencies in an LSTM-based Architecture\relax }{chapter.93}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {94}Ranking Kernels for Structures and Embeddings: A Hybrid Preference and Classification Model}{906}{chapter.94}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_797}{{94}{906}{Ranking Kernels for Structures and Embeddings: A Hybrid Preference and Classification Model\relax }{chapter.94}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {95}Recovering Question Answering Errors via Query Revision}{912}{chapter.95}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1405}{{95}{912}{Recovering Question Answering Errors via Query Revision\relax }{chapter.95}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {96}An empirical study on the effectiveness of images in Multimodal Neural Machine Translation}{919}{chapter.96}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1026}{{96}{919}{An empirical study on the effectiveness of images in Multimodal Neural Machine Translation\relax }{chapter.96}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {97}Sound-Word2Vec: Learning Word Representations Grounded in Sounds}{929}{chapter.97}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1037}{{97}{929}{Sound-Word2Vec: Learning Word Representations Grounded in Sounds\relax }{chapter.97}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {98}The Promise of Premise: Harnessing Question Premises in Visual Question Answering}{935}{chapter.98}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_7}{{98}{935}{The Promise of Premise: Harnessing Question Premises in Visual Question Answering\relax }{chapter.98}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {99}Guided Open Vocabulary Image Captioning with Constrained Beam Search}{945}{chapter.99}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_169}{{99}{945}{Guided Open Vocabulary Image Captioning with Constrained Beam Search\relax }{chapter.99}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {100}Zero-Shot Activity Recognition with Verb Attribute Induction}{955}{chapter.100}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1459}{{100}{955}{Zero-Shot Activity Recognition with Verb Attribute Induction\relax }{chapter.100}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {101}Deriving continous grounded meaning representations from referentially structured multimodal contexts}{968}{chapter.101}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_553}{{101}{968}{Deriving continous grounded meaning representations from referentially structured multimodal contexts\relax }{chapter.101}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {102}Hierarchically-Attentive RNN for Album Summarization and Storytelling}{975}{chapter.102}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1151}{{102}{975}{Hierarchically-Attentive RNN for Album Summarization and Storytelling\relax }{chapter.102}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {103}Video Highlight Prediction Using Audience Chat Reactions}{981}{chapter.103}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1223}{{103}{981}{Video Highlight Prediction Using Audience Chat Reactions\relax }{chapter.103}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {104}Reinforced Video Captioning with Entailment Rewards}{988}{chapter.104}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1296}{{104}{988}{Reinforced Video Captioning with Entailment Rewards\relax }{chapter.104}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {105}Evaluating Hierarchies of Verb Argument Structure with Hierarchical Clustering}{995}{chapter.105}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1446}{{105}{995}{Evaluating Hierarchies of Verb Argument Structure with Hierarchical Clustering\relax }{chapter.105}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {106}Incorporating Global Visual Features into Attention-based Neural Machine Translation.}{1001}{chapter.106}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_163}{{106}{1001}{Incorporating Global Visual Features into Attention-based Neural Machine Translation}{chapter.106}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {107}Mapping Instructions and Visual Observations to Actions with Reinforcement Learning}{1013}{chapter.107}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_138}{{107}{1013}{Mapping Instructions and Visual Observations to Actions with Reinforcement Learning\relax }{chapter.107}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {108}An analysis of eye-movements during reading for the detection of mild cognitive impairment}{1025}{chapter.108}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_301}{{108}{1025}{An analysis of eye-movements during reading for the detection of mild cognitive impairment\relax }{chapter.108}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {109}A Structured Learning Approach to Temporal Relation Extraction}{1036}{chapter.109}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_504}{{109}{1036}{A Structured Learning Approach to Temporal Relation Extraction\relax }{chapter.109}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {110}Importance sampling for unbiased on-demand evaluation of knowledge base population}{1047}{chapter.110}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1376}{{110}{1047}{Importance sampling for unbiased on-demand evaluation of knowledge base population\relax }{chapter.110}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {111}PACRR: A Position-Aware Neural IR Model for Relevance Matching}{1058}{chapter.111}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_961}{{111}{1058}{PACRR: A Position-Aware Neural IR Model for Relevance Matching\relax }{chapter.111}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {112}Globally Normalized Reader}{1068}{chapter.112}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_506}{{112}{1068}{Globally Normalized Reader\relax }{chapter.112}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {113}Speech segmentation with a neural encoder model of working memory}{1079}{chapter.113}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_445}{{113}{1079}{Speech segmentation with a neural encoder model of working memory\relax }{chapter.113}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {114}Speaking, Seeing, Understanding: Correlating semantic models with conceptual representation in the brain}{1090}{chapter.114}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_959}{{114}{1090}{Speaking, Seeing, Understanding: Correlating semantic models with conceptual representation in the brain\relax }{chapter.114}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {115}Multi-modal Summarization for Asynchronous Collection of Text, Image, Audio and Video}{1101}{chapter.115}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_75}{{115}{1101}{Multi-modal Summarization for Asynchronous Collection of Text, Image, Audio and Video\relax }{chapter.115}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {116}Tensor Fusion Network for Multimodal Sentiment Analysis}{1112}{chapter.116}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1400}{{116}{1112}{Tensor Fusion Network for Multimodal Sentiment Analysis\relax }{chapter.116}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {117}ConStance: Modeling Annotation Contexts to Improve Stance Classification}{1124}{chapter.117}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_412}{{117}{1124}{ConStance: Modeling Annotation Contexts to Improve Stance Classification\relax }{chapter.117}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {118}Deeper Attention to Abusive User Content Moderation}{1134}{chapter.118}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_909}{{118}{1134}{Deeper Attention to Abusive User Content Moderation\relax }{chapter.118}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {119}Outta Control: Laws of Semantic Change and Inherent Biases in Word Representation Models}{1145}{chapter.119}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_659}{{119}{1145}{Outta Control: Laws of Semantic Change and Inherent Biases in Word Representation Models\relax }{chapter.119}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {120}Human Centered NLP with User-Factor Adaptation}{1155}{chapter.120}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_391}{{120}{1155}{Human Centered NLP with User-Factor Adaptation\relax }{chapter.120}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {121}Neural Sequence Learning Models for Word Sense Disambiguation}{1165}{chapter.121}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_566}{{121}{1165}{Neural Sequence Learning Models for Word Sense Disambiguation\relax }{chapter.121}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {122}Learning Word Relatedness over Time}{1177}{chapter.122}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_962}{{122}{1177}{Learning Word Relatedness over Time\relax }{chapter.122}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {123}Inter-Weighted Alignment Network for Sentence Pair Modeling}{1188}{chapter.123}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_117}{{123}{1188}{Inter-Weighted Alignment Network for Sentence Pair Modeling\relax }{chapter.123}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {124}A Short Survey on Taxonomy Learning from Text Corpora: Issues, Resources and Recent Advances}{1199}{chapter.124}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_120}{{124}{1199}{A Short Survey on Taxonomy Learning from Text Corpora: Issues, Resources and Recent Advances\relax }{chapter.124}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {125}Idiom-Aware Compositional Distributed Semantics}{1213}{chapter.125}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_811}{{125}{1213}{Idiom-Aware Compositional Distributed Semantics\relax }{chapter.125}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {126}Macro Grammars and Holistic Triggering for Efficient Semantic Parsing}{1223}{chapter.126}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_982}{{126}{1223}{Macro Grammars and Holistic Triggering for Efficient Semantic Parsing\relax }{chapter.126}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {127}A Continuously Growing Dataset of Sentential Paraphrases}{1233}{chapter.127}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1042}{{127}{1233}{A Continuously Growing Dataset of Sentential Paraphrases\relax }{chapter.127}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {128}Cross-domain Semantic Parsing via Paraphrasing}{1244}{chapter.128}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1048}{{128}{1244}{Cross-domain Semantic Parsing via Paraphrasing\relax }{chapter.128}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {129}A Joint Sequential and Relational Model for Frame-Semantic Parsing}{1256}{chapter.129}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1087}{{129}{1256}{A Joint Sequential and Relational Model for Frame-Semantic Parsing\relax }{chapter.129}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {130}Getting the Most out of AMR Parsing}{1266}{chapter.130}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1407}{{130}{1266}{Getting the Most out of AMR Parsing\relax }{chapter.130}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {131}AMR Parsing using Stack-LSTMs}{1278}{chapter.131}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_820}{{131}{1278}{AMR Parsing using Stack-LSTMs\relax }{chapter.131}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {132}An End-to-End Deep Framework for Answer Triggering with a Novel Group-Level Objective}{1285}{chapter.132}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1134}{{132}{1285}{An End-to-End Deep Framework for Answer Triggering with a Novel Group-Level Objective\relax }{chapter.132}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {133}Predicting Word Association Strengths}{1292}{chapter.133}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1443}{{133}{1292}{Predicting Word Association Strengths\relax }{chapter.133}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {134}Learning Contextually Informed Representations for Linear-Time Discourse Parsing}{1298}{chapter.134}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_204}{{134}{1298}{Learning Contextually Informed Representations for Linear-Time Discourse Parsing\relax }{chapter.134}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {135}Multi-task Attention-based Neural Networks for Implicit Discourse Relationship Representation and Identification}{1308}{chapter.135}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_732}{{135}{1308}{Multi-task Attention-based Neural Networks for Implicit Discourse Relationship Representation and Identification\relax }{chapter.135}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {136}Chinese Zero Pronoun Resolution with Deep Memory Network}{1318}{chapter.136}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_751}{{136}{1318}{Chinese Zero Pronoun Resolution with Deep Memory Network\relax }{chapter.136}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {137}How much progress have we made on RST discourse parsing? A replication study of recent results on the RST-DT}{1328}{chapter.137}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_705}{{137}{1328}{How much progress have we made on RST discourse parsing? A replication study of recent results on the RST-DT\relax }{chapter.137}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {138}What is it? Disambiguating the different readings of the pronoun \IeC {\textquoteleft }it\IeC {\textquoteright }}{1334}{chapter.138}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_880}{{138}{1334}{What is it? Disambiguating the different readings of the pronoun ‘it’\relax }{chapter.138}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {139}Revisiting Selectional Preferences for Coreference Resolution}{1341}{chapter.139}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1019}{{139}{1341}{Revisiting Selectional Preferences for Coreference Resolution\relax }{chapter.139}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {140}Learning to Rank Semantic Coherence for Topic Segmentation}{1349}{chapter.140}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_497}{{140}{1349}{Learning to Rank Semantic Coherence for Topic Segmentation\relax }{chapter.140}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {141}GRASP: Rich Patterns for Argumentation Mining}{1354}{chapter.141}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_76}{{141}{1354}{GRASP: Rich Patterns for Argumentation Mining\relax }{chapter.141}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {142}Patterns of Argumentation Strategies across Topics}{1360}{chapter.142}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_425}{{142}{1360}{Patterns of Argumentation Strategies across Topics\relax }{chapter.142}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {143}Using Argument-based Features to Predict and Analyse Review Helpfulness}{1367}{chapter.143}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_286}{{143}{1367}{Using Argument-based Features to Predict and Analyse Review Helpfulness\relax }{chapter.143}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {144}Here's My Point: Joint Pointer Architecture for Argument Mining}{1373}{chapter.144}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1043}{{144}{1373}{Here's My Point: Joint Pointer Architecture for Argument Mining\relax }{chapter.144}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {145}Identifying attack and support argumentative relations using deep learning}{1383}{chapter.145}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_201}{{145}{1383}{Identifying attack and support argumentative relations using deep learning\relax }{chapter.145}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {146}Neural Lattice-to-Sequence Models for Uncertain Inputs}{1389}{chapter.146}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_223}{{146}{1389}{Neural Lattice-to-Sequence Models for Uncertain Inputs\relax }{chapter.146}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {147}Memory-augmented Neural Machine Translation}{1399}{chapter.147}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_277}{{147}{1399}{Memory-augmented Neural Machine Translation\relax }{chapter.147}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {148}Dynamic Data Selection for Neural Machine Translation}{1409}{chapter.148}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_372}{{148}{1409}{Dynamic Data Selection for Neural Machine Translation\relax }{chapter.148}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {149}Neural Machine Translation Leveraging Phrase-based Models in a Hybrid Search}{1420}{chapter.149}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_398}{{149}{1420}{Neural Machine Translation Leveraging Phrase-based Models in a Hybrid Search\relax }{chapter.149}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {150}Translating Phrases in Neural Machine Translation}{1430}{chapter.150}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_699}{{150}{1430}{Translating Phrases in Neural Machine Translation\relax }{chapter.150}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {151}Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation}{1441}{chapter.151}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_992}{{151}{1441}{Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation\relax }{chapter.151}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {152}Learning Translations via Matrix Completion}{1451}{chapter.152}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1161}{{152}{1451}{Learning Translations via Matrix Completion\relax }{chapter.152}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {153}Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback}{1463}{chapter.153}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1355}{{153}{1463}{Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback\relax }{chapter.153}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {154}Towards Compact and Fast Neural Machine Translation Using a Combined Method}{1474}{chapter.154}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_338}{{154}{1474}{Towards Compact and Fast Neural Machine Translation Using a Combined Method\relax }{chapter.154}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {155}Instance Weighting for Neural Machine Translation Domain Adaptation}{1481}{chapter.155}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_552}{{155}{1481}{Instance Weighting for Neural Machine Translation Domain Adaptation\relax }{chapter.155}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {156}Regularization techniques for fine-tuning in neural machine translation}{1488}{chapter.156}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_704}{{156}{1488}{Regularization techniques for fine-tuning in neural machine translation\relax }{chapter.156}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {157}Source-Side Left-to-Right or Target-Side Left-to-Right? An Empirical Comparison of Two Phrase-Based Decoding Algorithms}{1494}{chapter.157}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_744}{{157}{1494}{Source-Side Left-to-Right or Target-Side Left-to-Right? An Empirical Comparison of Two Phrase-Based Decoding Algorithms\relax }{chapter.157}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {158}Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning}{1499}{chapter.158}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_794}{{158}{1499}{Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning\relax }{chapter.158}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {159}Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling}{1505}{chapter.159}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_683}{{159}{1505}{Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling\relax }{chapter.159}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {160}Neural Semantic Parsing with Type Constraints for Semi-Structured Tables}{1515}{chapter.160}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1033}{{160}{1515}{Neural Semantic Parsing with Type Constraints for Semi-Structured Tables\relax }{chapter.160}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {161}Joint Concept Learning and Semantic Parsing from Natural Language Explanations}{1526}{chapter.161}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1255}{{161}{1526}{Joint Concept Learning and Semantic Parsing from Natural Language Explanations\relax }{chapter.161}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {162}Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection}{1536}{chapter.162}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_435}{{162}{1536}{Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection\relax }{chapter.162}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {163}Identifying civilians killed by police with distantly supervised entity-event extraction}{1546}{chapter.163}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_869}{{163}{1546}{Identifying civilians killed by police with distantly supervised entity-event extraction\relax }{chapter.163}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {164}Asking too much? The rhetorical role of questions in political discourse}{1557}{chapter.164}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1165}{{164}{1557}{Asking too much? The rhetorical role of questions in political discourse\relax }{chapter.164}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {165}Detecting Perspectives in Political Debates}{1572}{chapter.165}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_329}{{165}{1572}{Detecting Perspectives in Political Debates\relax }{chapter.165}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {166}"i have a feeling trump will win..................": Forecasting Winners and Losers from User Predictions on Twitter}{1582}{chapter.166}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1022}{{166}{1582}{"i have a feeling trump will win..................": Forecasting Winners and Losers from User Predictions on Twitter\relax }{chapter.166}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {167}A Question Answering Approach for Emotion Cause Extraction}{1592}{chapter.167}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_439}{{167}{1592}{A Question Answering Approach for Emotion Cause Extraction\relax }{chapter.167}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {168}Story Comprehension for Predicting What Happens Next}{1602}{chapter.168}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1138}{{168}{1602}{Story Comprehension for Predicting What Happens Next\relax }{chapter.168}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {169}Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm}{1614}{chapter.169}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_474}{{169}{1614}{Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm\relax }{chapter.169}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {170}Opinion Recommendation Using A Neural Model}{1625}{chapter.170}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1077}{{170}{1625}{Opinion Recommendation Using A Neural Model\relax }{chapter.170}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {171}CRF Autoencoder for Unsupervised Dependency Parsing}{1637}{chapter.171}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_836}{{171}{1637}{CRF Autoencoder for Unsupervised Dependency Parsing\relax }{chapter.171}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {172}Efficient Discontinuous Phrase-Structure Parsing via the Generalized Maximum Spanning Arborescence}{1643}{chapter.172}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_614}{{172}{1643}{Efficient Discontinuous Phrase-Structure Parsing via the Generalized Maximum Spanning Arborescence\relax }{chapter.172}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {173}Incremental Graph-based Neural Dependency Parsing}{1654}{chapter.173}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_720}{{173}{1654}{Incremental Graph-based Neural Dependency Parsing\relax }{chapter.173}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {174}Neural Discontinuous Constituency Parsing}{1665}{chapter.174}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1464}{{174}{1665}{Neural Discontinuous Constituency Parsing\relax }{chapter.174}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {175}Stack-based Multi-layer Attention for Transition-based Dependency Parsing}{1676}{chapter.175}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_638}{{175}{1676}{Stack-based Multi-layer Attention for Transition-based Dependency Parsing\relax }{chapter.175}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {176}Dependency Grammar Induction with Neural Lexicalization and Big Training Data}{1682}{chapter.176}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_654}{{176}{1682}{Dependency Grammar Induction with Neural Lexicalization and Big Training Data\relax }{chapter.176}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {177}Combining Generative and Discriminative Approaches to Unsupervised Dependency Parsing via Dual Decomposition}{1688}{chapter.177}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_361}{{177}{1688}{Combining Generative and Discriminative Approaches to Unsupervised Dependency Parsing via Dual Decomposition\relax }{chapter.177}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {178}Effective Inference for Generative Neural Parsing}{1694}{chapter.178}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1298}{{178}{1694}{Effective Inference for Generative Neural Parsing\relax }{chapter.178}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {179}Semi-supervised Structured Prediction with Neural CRF Autoencoder}{1700}{chapter.179}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_493}{{179}{1700}{Semi-supervised Structured Prediction with Neural CRF Autoencoder\relax }{chapter.179}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {180}TAG Parsing with Neural Networks and Vector Representations of Supertags}{1711}{chapter.180}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1377}{{180}{1711}{TAG Parsing with Neural Networks and Vector Representations of Supertags\relax }{chapter.180}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {181}Global Normalization of Convolutional Neural Networks for Joint Entity and Relation Classification}{1722}{chapter.181}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_343}{{181}{1722}{Global Normalization of Convolutional Neural Networks for Joint Entity and Relation Classification\relax }{chapter.181}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {182}End-to-End Neural Relation Extraction with Global Optimization}{1729}{chapter.182}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_308}{{182}{1729}{End-to-End Neural Relation Extraction with Global Optimization\relax }{chapter.182}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {183}KGEval: Accuracy Estimation of Automatically Constructed Knowledge Graphs}{1740}{chapter.183}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1289}{{183}{1740}{KGEval: Accuracy Estimation of Automatically Constructed Knowledge Graphs\relax }{chapter.183}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {184}Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short}{1750}{chapter.184}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1127}{{184}{1750}{Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short\relax }{chapter.184}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {185}Dual Tensor Model for Detecting Asymmetric Lexico-Semantic Relations}{1756}{chapter.185}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1056}{{185}{1756}{Dual Tensor Model for Detecting Asymmetric Lexico-Semantic Relations\relax }{chapter.185}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {186}Incorporating Relation Paths in Neural Relation Extraction}{1767}{chapter.186}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1333}{{186}{1767}{Incorporating Relation Paths in Neural Relation Extraction\relax }{chapter.186}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {187}Adversarial Training for Relation Extraction}{1777}{chapter.187}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_170}{{187}{1777}{Adversarial Training for Relation Extraction\relax }{chapter.187}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {188}Context-Aware Representations for Knowledge Base Relation Extraction}{1784}{chapter.188}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_306}{{188}{1784}{Context-Aware Representations for Knowledge Base Relation Extraction\relax }{chapter.188}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {189}A Soft-label Method for Noise-tolerant Distantly Supervised Relation Extraction}{1790}{chapter.189}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_826}{{189}{1790}{A Soft-label Method for Noise-tolerant Distantly Supervised Relation Extraction\relax }{chapter.189}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {190}A Sequential Model for Classifying Temporal Relations between Intra-Sentence Events}{1796}{chapter.190}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1006}{{190}{1796}{A Sequential Model for Classifying Temporal Relations between Intra-Sentence Events\relax }{chapter.190}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {191}Deep Residual Learning for Weakly-Supervised Relation Extraction}{1803}{chapter.191}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1222}{{191}{1803}{Deep Residual Learning for Weakly-Supervised Relation Extraction\relax }{chapter.191}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {192}Noise-Clustered Distant Supervision for Relation Extraction: A Nonparametric Bayesian Perspective}{1808}{chapter.192}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1305}{{192}{1808}{Noise-Clustered Distant Supervision for Relation Extraction: A Nonparametric Bayesian Perspective\relax }{chapter.192}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {193}Exploring Vector Spaces for Semantic Relations}{1814}{chapter.193}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_785}{{193}{1814}{Exploring Vector Spaces for Semantic Relations\relax }{chapter.193}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {194}Temporal dynamics of semantic relations in word embeddings: an application to predicting armed conflict participants}{1824}{chapter.194}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_686}{{194}{1824}{Temporal dynamics of semantic relations in word embeddings: an application to predicting armed conflict participants\relax }{chapter.194}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {195}Dynamic Entity Representations in Neural Language Models}{1830}{chapter.195}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1076}{{195}{1830}{Dynamic Entity Representations in Neural Language Models\relax }{chapter.195}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {196}Towards Quantum Language Models}{1840}{chapter.196}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_603}{{196}{1840}{Towards Quantum Language Models\relax }{chapter.196}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {197}Reference-Aware Language Models}{1850}{chapter.197}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_938}{{197}{1850}{Reference-Aware Language Models\relax }{chapter.197}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {198}A Simple Language Model based on PMI Matrix Approximations}{1860}{chapter.198}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_392}{{198}{1860}{A Simple Language Model based on PMI Matrix Approximations\relax }{chapter.198}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {199}Syllable-aware Neural Language Models: A Failure to Beat Character-aware Ones}{1866}{chapter.199}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_399}{{199}{1866}{Syllable-aware Neural Language Models: A Failure to Beat Character-aware Ones\relax }{chapter.199}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {200}Inducing Semantic Micro-Clusters from Deep Multi-View Representations of Novels}{1873}{chapter.200}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_629}{{200}{1873}{Inducing Semantic Micro-Clusters from Deep Multi-View Representations of Novels\relax }{chapter.200}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {201}Initializing Convolutional Filters with Semantic Features for Text Classification}{1884}{chapter.201}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_179}{{201}{1884}{Initializing Convolutional Filters with Semantic Features for Text Classification\relax }{chapter.201}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {202}Shortest-Path Graph Kernels for Document Similarity}{1890}{chapter.202}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_330}{{202}{1890}{Shortest-Path Graph Kernels for Document Similarity\relax }{chapter.202}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {203}Adapting Topic Models using Lexical Associations with Tree Priors}{1901}{chapter.203}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1075}{{203}{1901}{Adapting Topic Models using Lexical Associations with Tree Priors\relax }{chapter.203}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {204}Finding Patterns in Noisy Crowds: Regression-based Annotation Aggregation for Crowdsourced Data}{1907}{chapter.204}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1079}{{204}{1907}{Finding Patterns in Noisy Crowds: Regression-based Annotation Aggregation for Crowdsourced Data\relax }{chapter.204}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {205}CROWD-IN-THE-LOOP: A Hybrid Approach for Annotating Semantic Roles}{1913}{chapter.205}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_539}{{205}{1913}{CROWD-IN-THE-LOOP: A Hybrid Approach for Annotating Semantic Roles\relax }{chapter.205}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {206}Earth Mover's Distance Minimization for Unsupervised Bilingual Lexicon Induction}{1923}{chapter.206}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_543}{{206}{1923}{Earth Mover's Distance Minimization for Unsupervised Bilingual Lexicon Induction\relax }{chapter.206}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {207}Unfolding and Shrinking Neural Machine Translation Ensembles}{1935}{chapter.207}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_191}{{207}{1935}{Unfolding and Shrinking Neural Machine Translation Ensembles\relax }{chapter.207}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {208}Graph Convolutional Encoders for Syntax-aware Neural Machine Translation}{1946}{chapter.208}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_971}{{208}{1946}{Graph Convolutional Encoders for Syntax-aware Neural Machine Translation\relax }{chapter.208}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {209}Trainable Greedy Decoding for Neural Machine Translation}{1957}{chapter.209}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1297}{{209}{1957}{Trainable Greedy Decoding for Neural Machine Translation\relax }{chapter.209}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {210}Satirical News Detection and Analysis using Attention Mechanism and Linguistic Features}{1968}{chapter.210}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_455}{{210}{1968}{Satirical News Detection and Analysis using Attention Mechanism and Linguistic Features\relax }{chapter.210}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {211}Fine Grained Citation Span for References in Wikipedia}{1979}{chapter.211}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_299}{{211}{1979}{Fine Grained Citation Span for References in Wikipedia\relax }{chapter.211}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {212}Identifying Semantic Edit Intentions from Revisions in Wikipedia}{1989}{chapter.212}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_472}{{212}{1989}{Identifying Semantic Edit Intentions from Revisions in Wikipedia\relax }{chapter.212}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {213}Accurate Supervised and Semi-Supervised Machine Reading for Long Documents}{2000}{chapter.213}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_467}{{213}{2000}{Accurate Supervised and Semi-Supervised Machine Reading for Long Documents\relax }{chapter.213}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {214}Adversarial Examples for Evaluating Reading Comprehension Systems}{2010}{chapter.214}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1288}{{214}{2010}{Adversarial Examples for Evaluating Reading Comprehension Systems\relax }{chapter.214}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {215}Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension}{2021}{chapter.215}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_635}{{215}{2021}{Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension\relax }{chapter.215}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {216}Document-Level Multi-Aspect Sentiment Classification as Machine Comprehension}{2033}{chapter.216}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_177}{{216}{2033}{Document-Level Multi-Aspect Sentiment Classification as Machine Comprehension\relax }{chapter.216}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {217}What is the Essence of a Claim? Cross-Domain Claim Identification}{2044}{chapter.217}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_380}{{217}{2044}{What is the Essence of a Claim? Cross-Domain Claim Identification\relax }{chapter.217}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {218}Identifying Where to Focus in Reading Comprehension for Neural Question Generation}{2056}{chapter.218}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_206}{{218}{2056}{Identifying Where to Focus in Reading Comprehension for Neural Question Generation\relax }{chapter.218}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {219}Break it Down for Me: A Study in Automated Lyric Annotation}{2063}{chapter.219}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_730}{{219}{2063}{Break it Down for Me: A Study in Automated Lyric Annotation\relax }{chapter.219}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {220}Cascaded Attention based Unsupervised Information Distillation for Compressive Summarization}{2070}{chapter.220}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_246}{{220}{2070}{Cascaded Attention based Unsupervised Information Distillation for Compressive Summarization\relax }{chapter.220}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {221}Deep Recurrent Generative Decoder for Abstractive Text Summarization}{2080}{chapter.221}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_550}{{221}{2080}{Deep Recurrent Generative Decoder for Abstractive Text Summarization\relax }{chapter.221}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {222}Extractive Summarization Using Multi-Task Learning with Document Classification}{2090}{chapter.222}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1132}{{222}{2090}{Extractive Summarization Using Multi-Task Learning with Document Classification\relax }{chapter.222}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {223}Towards Automatic Construction of News Overview Articles by News Synthesis}{2100}{chapter.223}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_147}{{223}{2100}{Towards Automatic Construction of News Overview Articles by News Synthesis\relax }{chapter.223}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {224}Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank}{2106}{chapter.224}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1495}{{224}{2106}{Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank\relax }{chapter.224}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {225}Event Coreference Resolution by Iteratively Unfolding Inter-dependencies among Events}{2113}{chapter.225}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_970}{{225}{2113}{Event Coreference Resolution by Iteratively Unfolding Inter-dependencies among Events\relax }{chapter.225}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {226}Steering Output Style and Topic in Neural Response Generation}{2123}{chapter.226}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1380}{{226}{2123}{Steering Output Style and Topic in Neural Response Generation\relax }{chapter.226}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {227}Preserving Distributional Information in Dialogue Act Classification}{2134}{chapter.227}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1397}{{227}{2134}{Preserving Distributional Information in Dialogue Act Classification\relax }{chapter.227}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {228}Adversarial Learning for Neural Dialogue Generation}{2140}{chapter.228}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_11}{{228}{2140}{Adversarial Learning for Neural Dialogue Generation\relax }{chapter.228}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {229}Using Context Information for Dialog Act Classification in DNN Framework}{2153}{chapter.229}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_281}{{229}{2153}{Using Context Information for Dialog Act Classification in DNN Framework\relax }{chapter.229}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {230}Modeling Dialogue Acts with Content Word Filtering and Speaker Preferences}{2162}{chapter.230}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_519}{{230}{2162}{Modeling Dialogue Acts with Content Word Filtering and Speaker Preferences\relax }{chapter.230}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {231}Towards Implicit Content-Introducing for Generative Short-Text Conversation Systems}{2173}{chapter.231}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_689}{{231}{2173}{Towards Implicit Content-Introducing for Generative Short-Text Conversation Systems\relax }{chapter.231}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {232}Affordable On-line Dialogue Policy Learning}{2183}{chapter.232}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_697}{{232}{2183}{Affordable On-line Dialogue Policy Learning\relax }{chapter.232}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {233}Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models}{2193}{chapter.233}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_844}{{233}{2193}{Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models\relax }{chapter.233}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {234}Bootstrapping incremental dialogue systems from minimal data: the generalisation power of dialogue grammars}{2203}{chapter.234}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_956}{{234}{2203}{Bootstrapping incremental dialogue systems from minimal data: the generalisation power of dialogue grammars\relax }{chapter.234}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {235}Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning}{2214}{chapter.235}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1176}{{235}{2214}{Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning\relax }{chapter.235}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {236}Why We Need New Evaluation Metrics for NLG}{2224}{chapter.236}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_387}{{236}{2224}{Why We Need New Evaluation Metrics for NLG\relax }{chapter.236}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {237}Challenges in Data-to-Document Generation}{2236}{chapter.237}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1363}{{237}{2236}{Challenges in Data-to-Document Generation\relax }{chapter.237}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {238}All that is English may be Hindi: Enhancing language identification through automatic ranking of the likeliness of word borrowing in social media}{2247}{chapter.238}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_400}{{238}{2247}{All that is English may be Hindi: Enhancing language identification through automatic ranking of the likeliness of word borrowing in social media\relax }{chapter.238}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {239}Multi-View Unsupervised User Feature Embedding for Social Media-based Substance Use Prediction}{2258}{chapter.239}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_714}{{239}{2258}{Multi-View Unsupervised User Feature Embedding for Social Media-based Substance Use Prediction\relax }{chapter.239}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {240}Demographic-aware word associations}{2268}{chapter.240}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_792}{{240}{2268}{Demographic-aware word associations\relax }{chapter.240}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {241}A Factored Neural Network Model for Characterizing Online Discussions in Vector Space}{2279}{chapter.241}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1062}{{241}{2279}{A Factored Neural Network Model for Characterizing Online Discussions in Vector Space\relax }{chapter.241}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {242}Dimensions of Interpersonal Relationships: Corpus and Experiments}{2290}{chapter.242}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1163}{{242}{2290}{Dimensions of Interpersonal Relationships: Corpus and Experiments\relax }{chapter.242}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {243}Argument Mining on Twitter: Arguments, Facts and Sources}{2300}{chapter.243}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_934}{{243}{2300}{Argument Mining on Twitter: Arguments, Facts and Sources\relax }{chapter.243}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {244}Distinguishing Japanese Non-standard Usages from Standard Ones}{2306}{chapter.244}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1159}{{244}{2306}{Distinguishing Japanese Non-standard Usages from Standard Ones\relax }{chapter.244}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {245}Connotation Frames of Power and Agency in Modern Films}{2312}{chapter.245}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1327}{{245}{2312}{Connotation Frames of Power and Agency in Modern Films\relax }{chapter.245}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {246}Controlling Human Perception of Basic User Traits}{2318}{chapter.246}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1415}{{246}{2318}{Controlling Human Perception of Basic User Traits\relax }{chapter.246}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {247}Topic Signatures in Political Campaign Speeches}{2325}{chapter.247}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_581}{{247}{2325}{Topic Signatures in Political Campaign Speeches\relax }{chapter.247}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {248}Assessing Objective Recommendation Quality through Political Forecasting}{2331}{chapter.248}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_501}{{248}{2331}{Assessing Objective Recommendation Quality through Political Forecasting\relax }{chapter.248}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {249}Never Abandon Minorities: Exhaustive Extraction of Bursty Phrases on Microblogs Using Set Cover Problem}{2341}{chapter.249}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_536}{{249}{2341}{Never Abandon Minorities: Exhaustive Extraction of Bursty Phrases on Microblogs Using Set Cover Problem\relax }{chapter.249}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {250}Maximum Margin Reward Networks for Learning from Explicit and Implicit Supervision}{2351}{chapter.250}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1310}{{250}{2351}{Maximum Margin Reward Networks for Learning from Explicit and Implicit Supervision\relax }{chapter.250}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {251}The Impact of Modeling Overall Argumentation with Tree Kernels}{2362}{chapter.251}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_349}{{251}{2362}{The Impact of Modeling Overall Argumentation with Tree Kernels\relax }{chapter.251}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {252}Learning Generic Sentence Representations Using Convolutional Neural Networks}{2373}{chapter.252}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_977}{{252}{2373}{Learning Generic Sentence Representations Using Convolutional Neural Networks\relax }{chapter.252}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {253}Repeat before Forgetting: Spaced Repetition for Efficient and Effective Training of Neural Networks}{2384}{chapter.253}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_916}{{253}{2384}{Repeat before Forgetting: Spaced Repetition for Efficient and Effective Training of Neural Networks\relax }{chapter.253}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {254}Part-of-Speech Tagging for Twitter with Adversarial Neural Networks}{2394}{chapter.254}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_264}{{254}{2394}{Part-of-Speech Tagging for Twitter with Adversarial Neural Networks\relax }{chapter.254}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {255}Investigating Different Syntactic Context Types and Context Representations for Learning Word Embeddings}{2404}{chapter.255}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_559}{{255}{2404}{Investigating Different Syntactic Context Types and Context Representations for Learning Word Embeddings\relax }{chapter.255}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {256}Does syntax help discourse segmentation? Not so much}{2415}{chapter.256}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1113}{{256}{2415}{Does syntax help discourse segmentation? Not so much\relax }{chapter.256}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {257}Deal or No Deal? End-to-End Learning of Negotiation Dialogues}{2426}{chapter.257}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1270}{{257}{2426}{Deal or No Deal? End-to-End Learning of Negotiation Dialogues\relax }{chapter.257}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {258}Agent-Aware Dropout DQN for Safe and Efficient On-line Dialogue Policy Learning}{2437}{chapter.258}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1403}{{258}{2437}{Agent-Aware Dropout DQN for Safe and Efficient On-line Dialogue Policy Learning\relax }{chapter.258}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {259}Towards Debate Automation: a Recurrent Model for Predicting Debate Winners}{2448}{chapter.259}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1372}{{259}{2448}{Towards Debate Automation: a Recurrent Model for Predicting Debate Winners\relax }{chapter.259}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {260}Further Investigation into Reference Bias in Monolingual Evaluation of Machine Translation}{2459}{chapter.260}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_194}{{260}{2459}{Further Investigation into Reference Bias in Monolingual Evaluation of Machine Translation\relax }{chapter.260}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {261}A Challenge Set Approach to Evaluating Machine Translation}{2469}{chapter.261}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_477}{{261}{2469}{A Challenge Set Approach to Evaluating Machine Translation\relax }{chapter.261}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {262}Knowledge Distillation for Bilingual Dictionary Induction}{2480}{chapter.262}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1274}{{262}{2480}{Knowledge Distillation for Bilingual Dictionary Induction\relax }{chapter.262}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {263}Machine Translation, it's a question of style, innit? The case of English tag questions}{2490}{chapter.263}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1073}{{263}{2490}{Machine Translation, it's a question of style, innit? The case of English tag questions\relax }{chapter.263}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {264}Deciphering Related Languages}{2496}{chapter.264}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1236}{{264}{2496}{Deciphering Related Languages\relax }{chapter.264}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {265}Identifying Cognate Sets Across Dictionaries of Related Languages}{2502}{chapter.265}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1131}{{265}{2502}{Identifying Cognate Sets Across Dictionaries of Related Languages\relax }{chapter.265}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {266}Learning Language Representations for Typology Prediction}{2512}{chapter.266}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1424}{{266}{2512}{Learning Language Representations for Typology Prediction\relax }{chapter.266}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {267}Cheap Translation for Cross-Lingual Named Entity Recognition}{2519}{chapter.267}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1023}{{267}{2519}{Cheap Translation for Cross-Lingual Named Entity Recognition\relax }{chapter.267}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {268}Cross-Lingual Induction and Transfer of Verb Classes Based on Word Vector Space Specialisation}{2529}{chapter.268}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_817}{{268}{2529}{Cross-Lingual Induction and Transfer of Verb Classes Based on Word Vector Space Specialisation\relax }{chapter.268}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {269}Classification of telicity using cross-linguistic annotation projection}{2542}{chapter.269}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_77}{{269}{2542}{Classification of telicity using cross-linguistic annotation projection\relax }{chapter.269}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {270}Counterfactual Learning from Bandit Feedback under Deterministic Logging : A Case Study in Statistical Machine Translation}{2549}{chapter.270}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_637}{{270}{2549}{Counterfactual Learning from Bandit Feedback under Deterministic Logging : A Case Study in Statistical Machine Translation\relax }{chapter.270}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {271}Learning Fine-grained Relations from Chinese User Generated Categories}{2560}{chapter.271}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_119}{{271}{2560}{Learning Fine-grained Relations from Chinese User Generated Categories\relax }{chapter.271}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {272}Improving Slot Filling Performance with Attentive Neural Networks on Dependency Structures}{2571}{chapter.272}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_142}{{272}{2571}{Improving Slot Filling Performance with Attentive Neural Networks on Dependency Structures\relax }{chapter.272}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {273}Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-grained Domain Adaptation}{2581}{chapter.273}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_529}{{273}{2581}{Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-grained Domain Adaptation\relax }{chapter.273}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {274}Labeling Gaps Between Words: Recognizing Overlapping Mentions with Mention Separators}{2591}{chapter.274}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_625}{{274}{2591}{Labeling Gaps Between Words: Recognizing Overlapping Mentions with Mention Separators\relax }{chapter.274}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {275}Deep Joint Entity Disambiguation with Local Neural Attention}{2602}{chapter.275}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1044}{{275}{2602}{Deep Joint Entity Disambiguation with Local Neural Attention\relax }{chapter.275}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {276}MinIE: Minimizing Facts in Open Information Extraction}{2613}{chapter.276}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1094}{{276}{2613}{MinIE: Minimizing Facts in Open Information Extraction\relax }{chapter.276}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {277}Scientific Information Extraction with Semi-supervised Neural Tagging}{2624}{chapter.277}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1301}{{277}{2624}{Scientific Information Extraction with Semi-supervised Neural Tagging\relax }{chapter.277}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {278}NITE: A Neural Inductive Teaching Framework for Domain Specific NER}{2635}{chapter.278}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_634}{{278}{2635}{NITE: A Neural Inductive Teaching Framework for Domain Specific NER\relax }{chapter.278}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {279}Speeding up Reinforcement Learning-based Information Extraction Training using Asynchronous Methods}{2641}{chapter.279}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1324}{{279}{2641}{Speeding up Reinforcement Learning-based Information Extraction Training using Asynchronous Methods\relax }{chapter.279}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {280}Leveraging Linguistic Structures for Named Entity Recognition with Bidirectional Recursive Neural Networks}{2647}{chapter.280}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1408}{{280}{2647}{Leveraging Linguistic Structures for Named Entity Recognition with Bidirectional Recursive Neural Networks\relax }{chapter.280}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {281}Fast and Accurate Entity Recognition with Iterated Dilated Convolutions}{2653}{chapter.281}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1005}{{281}{2653}{Fast and Accurate Entity Recognition with Iterated Dilated Convolutions\relax }{chapter.281}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {282}Entity Linking via Joint Encoding of Types, Descriptions, and Context}{2664}{chapter.282}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1356}{{282}{2664}{Entity Linking via Joint Encoding of Types, Descriptions, and Context\relax }{chapter.282}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {283}An Insight Extraction System on BioMedical Literature with Deep Neural Networks}{2674}{chapter.283}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1295}{{283}{2674}{An Insight Extraction System on BioMedical Literature with Deep Neural Networks\relax }{chapter.283}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {284}Word Etymology as Native Language Interference}{2685}{chapter.284}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_642}{{284}{2685}{Word Etymology as Native Language Interference\relax }{chapter.284}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {285}A Simpler and More Generalizable Story Detector using Verb and Character Features}{2691}{chapter.285}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_49}{{285}{2691}{A Simpler and More Generalizable Story Detector using Verb and Character Features\relax }{chapter.285}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {286}Multi-modular domain-tailored OCR post-correction}{2699}{chapter.286}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_236}{{286}{2699}{Multi-modular domain-tailored OCR post-correction\relax }{chapter.286}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {287}Learning to Predict Charges for Criminal Cases with Legal Basis}{2710}{chapter.287}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_282}{{287}{2710}{Learning to Predict Charges for Criminal Cases with Legal Basis\relax }{chapter.287}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {288}Quantifying the Effects of Text Duplication on Semantic Models}{2720}{chapter.288}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_488}{{288}{2720}{Quantifying the Effects of Text Duplication on Semantic Models\relax }{chapter.288}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {289}Identifying Semantically Deviating Outlier Documents}{2731}{chapter.289}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_674}{{289}{2731}{Identifying Semantically Deviating Outlier Documents\relax }{chapter.289}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {290}Detecting and Explaining Causes From Text For a Time Series Event}{2741}{chapter.290}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1184}{{290}{2741}{Detecting and Explaining Causes From Text For a Time Series Event\relax }{chapter.290}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {291}A Novel Cascade Model for Learning Latent Similarity from Heterogeneous Sequential Data of MOOC}{2751}{chapter.291}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_247}{{291}{2751}{A Novel Cascade Model for Learning Latent Similarity from Heterogeneous Sequential Data of MOOC\relax }{chapter.291}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {292}Identifying the Provision of Choices in Privacy Policy Text}{2757}{chapter.292}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_747}{{292}{2757}{Identifying the Provision of Choices in Privacy Policy Text\relax }{chapter.292}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {293}An Empirical Analysis of Edit Importance between Document Versions}{2763}{chapter.293}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_986}{{293}{2763}{An Empirical Analysis of Edit Importance between Document Versions\relax }{chapter.293}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {294}Transition-Based Disfluency Detection using LSTMs}{2768}{chapter.294}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1013}{{294}{2768}{Transition-Based Disfluency Detection using LSTMs\relax }{chapter.294}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {295}Neural Sequence-Labelling Models for Grammatical Error Correction}{2778}{chapter.295}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_457}{{295}{2778}{Neural Sequence-Labelling Models for Grammatical Error Correction\relax }{chapter.295}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {296}Adapting Sequence Models for Sentence Correction}{2790}{chapter.296}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1254}{{296}{2790}{Adapting Sequence Models for Sentence Correction\relax }{chapter.296}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {297}A Study of Style in Machine Translation: Controlling the Formality of Machine Translation Output}{2797}{chapter.297}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1411}{{297}{2797}{A Study of Style in Machine Translation: Controlling the Formality of Machine Translation Output\relax }{chapter.297}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {298}Sharp Models on Dull Hardware: Fast and Accurate Neural Machine Translation Decoding on the CPU}{2803}{chapter.298}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_469}{{298}{2803}{Sharp Models on Dull Hardware: Fast and Accurate Neural Machine Translation Decoding on the CPU\relax }{chapter.298}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {299}Exploiting Cross-Sentence Context for Neural Machine Translation}{2809}{chapter.299}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_716}{{299}{2809}{Exploiting Cross-Sentence Context for Neural Machine Translation\relax }{chapter.299}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {300}Cross-Lingual Transfer Learning for POS Tagging without Cross-Lingual Resources}{2815}{chapter.300}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1511}{{300}{2815}{Cross-Lingual Transfer Learning for POS Tagging without Cross-Lingual Resources\relax }{chapter.300}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {301}Image Pivoting for Learning Multilingual Multimodal Representations}{2822}{chapter.301}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_644}{{301}{2822}{Image Pivoting for Learning Multilingual Multimodal Representations\relax }{chapter.301}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {302}Neural Machine Translation with Source Dependency Representation}{2829}{chapter.302}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_538}{{302}{2829}{Neural Machine Translation with Source Dependency Representation\relax }{chapter.302}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {303}Visual Denotations for Recognizing Textual Entailment}{2836}{chapter.303}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1388}{{303}{2836}{Visual Denotations for Recognizing Textual Entailment\relax }{chapter.303}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {304}Sequence Effects in Crowdsourced Annotations}{2843}{chapter.304}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1430}{{304}{2843}{Sequence Effects in Crowdsourced Annotations\relax }{chapter.304}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {305}No Need to Pay Attention: Simple Recurrent Neural Networks Work!}{2849}{chapter.305}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1017}{{305}{2849}{No Need to Pay Attention: Simple Recurrent Neural Networks Work!\relax }{chapter.305}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {306}The strange geometry of skip-gram with negative sampling}{2856}{chapter.306}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_888}{{306}{2856}{The strange geometry of skip-gram with negative sampling\relax }{chapter.306}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {307}Natural Language Processing with Small Feed-Forward Networks}{2862}{chapter.307}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1281}{{307}{2862}{Natural Language Processing with Small Feed-Forward Networks\relax }{chapter.307}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {308}Deep Multi-Task Learning for Aspect Term Extraction with Memory Interaction}{2869}{chapter.308}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1318}{{308}{2869}{Deep Multi-Task Learning for Aspect Term Extraction with Memory Interaction\relax }{chapter.308}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {309}Analogs of Linguistic Structure in Deep Representations}{2876}{chapter.309}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_300}{{309}{2876}{Analogs of Linguistic Structure in Deep Representations\relax }{chapter.309}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {310}A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings}{2881}{chapter.310}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1249}{{310}{2881}{A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings\relax }{chapter.310}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {311}Learning what to read: Focused machine reading}{2888}{chapter.311}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1188}{{311}{2888}{Learning what to read: Focused machine reading\relax }{chapter.311}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {312}DOC: Deep Open Classification of Text Documents}{2894}{chapter.312}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1420}{{312}{2894}{DOC: Deep Open Classification of Text Documents\relax }{chapter.312}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {313}Charmanteau: Character Embedding Models For Portmanteau Creation}{2900}{chapter.313}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_852}{{313}{2900}{Charmanteau: Character Embedding Models For Portmanteau Creation\relax }{chapter.313}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {314}Using Automated Metaphor Identification to Aid in Detection and Prediction of First-Episode Schizophrenia}{2906}{chapter.314}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_709}{{314}{2906}{Using Automated Metaphor Identification to Aid in Detection and Prediction of First-Episode Schizophrenia\relax }{chapter.314}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {315}Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking}{2914}{chapter.315}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1326}{{315}{2914}{Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking\relax }{chapter.315}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {316}Topic-Based Agreement and Disagreement in US Electoral Manifestos}{2921}{chapter.316}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_196}{{316}{2921}{Topic-Based Agreement and Disagreement in US Electoral Manifestos\relax }{chapter.316}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {317}Zipporah: a Fast and Scalable Data Cleaning System for Noisy Web-Crawled Parallel Corpora}{2928}{chapter.317}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_476}{{317}{2928}{Zipporah: a Fast and Scalable Data Cleaning System for Noisy Web-Crawled Parallel Corpora\relax }{chapter.317}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {318}Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints}{2934}{chapter.318}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_1470}{{318}{2934}{Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints\relax }{chapter.318}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {319}Natural Language Does Not Emerge \IeC {\textquoteleft }Naturally\IeC {\textquoteright } in Multi-Agent Dialog}{2945}{chapter.319}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_505}{{319}{2945}{Natural Language Does Not Emerge ‘Naturally’ in Multi-Agent Dialog\relax }{chapter.319}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {320}Depression and Self-Harm Risk Assessment in Online Forums}{2951}{chapter.320}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_633}{{320}{2951}{Depression and Self-Harm Risk Assessment in Online Forums\relax }{chapter.320}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {321}Bringing Structure into Summaries: Crowdsourcing a Benchmark Corpus of Concept Maps}{2962}{chapter.321}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:paper_341}{{321}{2962}{Bringing Structure into Summaries: Crowdsourcing a Benchmark Corpus of Concept Maps\relax }{chapter.321}{}}
\@setckpt{allpapers}{
\setcounter{page}{2973}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{321}
\setcounter{section}{0}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{AM@survey}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{section@level}{0}
}
